{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "def encode_text_dummy(df,name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name,x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "def encode_text_single_dummy(df,name,target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x)==str(tv) else 0 for x in l]\n",
    "        name2 = \"{}-{}\".format(name,tv)\n",
    "        df[name2] = l\n",
    "    \n",
    "def encode_text_index(df,name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "def encode_numeric_zscore(df,name,mean=None,sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name]-mean)/sd\n",
    "\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "def to_xy(df,target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    \n",
    "    if target_type in (np.int64, np.int32):\n",
    "        return df.as_matrix(result).astype(np.float32),df.as_matrix([target]).astype(np.int32)\n",
    "    else:\n",
    "        return df.as_matrix(result).astype(np.float32),df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 0.18995149433612823\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin-1</th>\n",
       "      <th>origin-2</th>\n",
       "      <th>origin-3</th>\n",
       "      <th>pred</th>\n",
       "      <th>ideal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.496308</td>\n",
       "      <td>1.089233</td>\n",
       "      <td>0.672271</td>\n",
       "      <td>0.630077</td>\n",
       "      <td>-1.293870</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.913458</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.496308</td>\n",
       "      <td>1.501624</td>\n",
       "      <td>1.587959</td>\n",
       "      <td>0.853259</td>\n",
       "      <td>-1.475181</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.878858</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.496308</td>\n",
       "      <td>1.194728</td>\n",
       "      <td>1.195522</td>\n",
       "      <td>0.549778</td>\n",
       "      <td>-1.656492</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.878546</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>1.496308</td>\n",
       "      <td>1.060461</td>\n",
       "      <td>1.195522</td>\n",
       "      <td>0.546236</td>\n",
       "      <td>-1.293870</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.882986</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.496308</td>\n",
       "      <td>1.041280</td>\n",
       "      <td>0.933897</td>\n",
       "      <td>0.565130</td>\n",
       "      <td>-1.837804</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.907516</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.496308</td>\n",
       "      <td>2.259274</td>\n",
       "      <td>2.451322</td>\n",
       "      <td>1.618455</td>\n",
       "      <td>-2.019115</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.791887</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.496308</td>\n",
       "      <td>2.499036</td>\n",
       "      <td>3.026898</td>\n",
       "      <td>1.633806</td>\n",
       "      <td>-2.381737</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.774524</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.496308</td>\n",
       "      <td>2.364769</td>\n",
       "      <td>2.896085</td>\n",
       "      <td>1.584210</td>\n",
       "      <td>-2.563048</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.781412</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.496308</td>\n",
       "      <td>2.508627</td>\n",
       "      <td>3.157710</td>\n",
       "      <td>1.717647</td>\n",
       "      <td>-2.019115</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.739818</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.496308</td>\n",
       "      <td>1.885244</td>\n",
       "      <td>2.242022</td>\n",
       "      <td>1.038654</td>\n",
       "      <td>-2.563048</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.849905</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.496308</td>\n",
       "      <td>1.818111</td>\n",
       "      <td>1.718772</td>\n",
       "      <td>0.699747</td>\n",
       "      <td>-2.019115</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.942660</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.496308</td>\n",
       "      <td>1.405719</td>\n",
       "      <td>1.457147</td>\n",
       "      <td>0.754067</td>\n",
       "      <td>-2.744360</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.937535</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.496308</td>\n",
       "      <td>1.981149</td>\n",
       "      <td>1.195522</td>\n",
       "      <td>0.933557</td>\n",
       "      <td>-2.200426</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.010536</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.496308</td>\n",
       "      <td>2.508627</td>\n",
       "      <td>3.157710</td>\n",
       "      <td>0.136478</td>\n",
       "      <td>-2.019115</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.949841</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.771324</td>\n",
       "      <td>-0.243417</td>\n",
       "      <td>-0.706655</td>\n",
       "      <td>-0.206002</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.798086</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.320532</td>\n",
       "      <td>0.043868</td>\n",
       "      <td>-0.243417</td>\n",
       "      <td>-0.162279</td>\n",
       "      <td>-0.024691</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.855574</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.320532</td>\n",
       "      <td>0.053459</td>\n",
       "      <td>-0.191092</td>\n",
       "      <td>-0.231950</td>\n",
       "      <td>-0.024691</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.903589</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.320532</td>\n",
       "      <td>0.063049</td>\n",
       "      <td>-0.505042</td>\n",
       "      <td>-0.452770</td>\n",
       "      <td>0.156620</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.940790</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>27.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.924773</td>\n",
       "      <td>-0.426554</td>\n",
       "      <td>-0.992422</td>\n",
       "      <td>-0.387314</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.814463</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.924773</td>\n",
       "      <td>-1.525380</td>\n",
       "      <td>-1.340775</td>\n",
       "      <td>1.788421</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.975174</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.800096</td>\n",
       "      <td>-0.452717</td>\n",
       "      <td>-0.352397</td>\n",
       "      <td>0.700554</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.749441</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.828867</td>\n",
       "      <td>-0.374229</td>\n",
       "      <td>-0.638165</td>\n",
       "      <td>-0.387314</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23.818041</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>25.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.857639</td>\n",
       "      <td>-0.243417</td>\n",
       "      <td>-0.703112</td>\n",
       "      <td>0.700554</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.765955</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>26.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.694600</td>\n",
       "      <td>0.227509</td>\n",
       "      <td>-0.869613</td>\n",
       "      <td>-1.112559</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.792355</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.320532</td>\n",
       "      <td>0.053459</td>\n",
       "      <td>-0.374229</td>\n",
       "      <td>-0.380738</td>\n",
       "      <td>-0.206002</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.921858</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.496308</td>\n",
       "      <td>1.597529</td>\n",
       "      <td>2.896085</td>\n",
       "      <td>1.942010</td>\n",
       "      <td>-0.568625</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.124063</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.496308</td>\n",
       "      <td>1.089233</td>\n",
       "      <td>2.503648</td>\n",
       "      <td>1.659785</td>\n",
       "      <td>-0.206002</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.234016</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.496308</td>\n",
       "      <td>1.194728</td>\n",
       "      <td>2.765273</td>\n",
       "      <td>1.666870</td>\n",
       "      <td>-0.749936</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.845525</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.496308</td>\n",
       "      <td>1.060461</td>\n",
       "      <td>2.320510</td>\n",
       "      <td>2.080171</td>\n",
       "      <td>1.063176</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.491858</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>27.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.924773</td>\n",
       "      <td>-0.426554</td>\n",
       "      <td>-0.992422</td>\n",
       "      <td>-0.387314</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.818274</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>27.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.780915</td>\n",
       "      <td>-0.426554</td>\n",
       "      <td>-0.390185</td>\n",
       "      <td>1.099439</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.714170</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>34.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.780915</td>\n",
       "      <td>-0.426554</td>\n",
       "      <td>-0.679495</td>\n",
       "      <td>0.881865</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.687473</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>31.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.780915</td>\n",
       "      <td>-0.505042</td>\n",
       "      <td>-0.466940</td>\n",
       "      <td>0.229145</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.716448</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>29.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.560333</td>\n",
       "      <td>-0.531204</td>\n",
       "      <td>-0.525983</td>\n",
       "      <td>0.156620</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.783884</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>27.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.406885</td>\n",
       "      <td>-0.374229</td>\n",
       "      <td>-0.278003</td>\n",
       "      <td>0.881865</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.750744</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>24.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.512381</td>\n",
       "      <td>-0.321904</td>\n",
       "      <td>-0.124492</td>\n",
       "      <td>0.301669</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.754368</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>23.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.406885</td>\n",
       "      <td>-0.282660</td>\n",
       "      <td>0.076254</td>\n",
       "      <td>1.788421</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.704788</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>36.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.848048</td>\n",
       "      <td>-0.792829</td>\n",
       "      <td>-1.169551</td>\n",
       "      <td>-0.097216</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.856297</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>37.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.982316</td>\n",
       "      <td>-0.949804</td>\n",
       "      <td>-1.116412</td>\n",
       "      <td>0.954390</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.793159</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>31.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.982316</td>\n",
       "      <td>-0.949804</td>\n",
       "      <td>-1.181360</td>\n",
       "      <td>0.736816</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.873365</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>38.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.848048</td>\n",
       "      <td>-1.080617</td>\n",
       "      <td>-0.998327</td>\n",
       "      <td>-0.314789</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.799049</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>36.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.915182</td>\n",
       "      <td>-0.897479</td>\n",
       "      <td>-0.998327</td>\n",
       "      <td>0.628029</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.761387</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>36.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.704191</td>\n",
       "      <td>-0.426554</td>\n",
       "      <td>-0.956997</td>\n",
       "      <td>-0.387314</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.789833</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>36.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.828867</td>\n",
       "      <td>-0.766667</td>\n",
       "      <td>-0.903858</td>\n",
       "      <td>-0.387314</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.807884</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>34.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.819277</td>\n",
       "      <td>-0.897479</td>\n",
       "      <td>-0.856624</td>\n",
       "      <td>0.482980</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.816803</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>38.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.982316</td>\n",
       "      <td>-0.975967</td>\n",
       "      <td>-1.187264</td>\n",
       "      <td>-0.206002</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.828106</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>32.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.982316</td>\n",
       "      <td>-0.975967</td>\n",
       "      <td>-1.187264</td>\n",
       "      <td>0.047833</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.885767</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>38.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.982316</td>\n",
       "      <td>-0.975967</td>\n",
       "      <td>-1.151838</td>\n",
       "      <td>0.229145</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.810921</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.320532</td>\n",
       "      <td>-0.119170</td>\n",
       "      <td>0.149021</td>\n",
       "      <td>-0.030023</td>\n",
       "      <td>0.301669</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.766397</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.320532</td>\n",
       "      <td>0.657660</td>\n",
       "      <td>-0.505042</td>\n",
       "      <td>0.052637</td>\n",
       "      <td>0.519243</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.804516</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>26.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.358933</td>\n",
       "      <td>-0.321904</td>\n",
       "      <td>-0.455132</td>\n",
       "      <td>-0.387314</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.822718</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.320532</td>\n",
       "      <td>0.369945</td>\n",
       "      <td>0.201346</td>\n",
       "      <td>-0.159917</td>\n",
       "      <td>-0.314789</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.898605</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>32.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.474019</td>\n",
       "      <td>-0.217254</td>\n",
       "      <td>-0.360663</td>\n",
       "      <td>-0.604887</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.756998</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>36.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.560333</td>\n",
       "      <td>-0.531204</td>\n",
       "      <td>-0.709016</td>\n",
       "      <td>-0.931247</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.765396</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>27.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.406885</td>\n",
       "      <td>-0.374229</td>\n",
       "      <td>-0.024119</td>\n",
       "      <td>0.628029</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.720211</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.512381</td>\n",
       "      <td>-0.478879</td>\n",
       "      <td>-0.213056</td>\n",
       "      <td>0.011571</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.763346</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.924773</td>\n",
       "      <td>-1.368405</td>\n",
       "      <td>-0.992422</td>\n",
       "      <td>3.275173</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43.714481</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.560333</td>\n",
       "      <td>-0.531204</td>\n",
       "      <td>-0.797581</td>\n",
       "      <td>-1.438919</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.835516</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.704191</td>\n",
       "      <td>-0.662017</td>\n",
       "      <td>-0.407897</td>\n",
       "      <td>1.099439</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.747446</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>-0.855244</td>\n",
       "      <td>-0.713781</td>\n",
       "      <td>-0.583529</td>\n",
       "      <td>-0.295716</td>\n",
       "      <td>1.389537</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.679079</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower    weight  acceleration  year  \\\n",
       "0    18.0   1.496308      1.089233    0.672271  0.630077     -1.293870    70   \n",
       "1    15.0   1.496308      1.501624    1.587959  0.853259     -1.475181    70   \n",
       "2    18.0   1.496308      1.194728    1.195522  0.549778     -1.656492    70   \n",
       "3    16.0   1.496308      1.060461    1.195522  0.546236     -1.293870    70   \n",
       "4    17.0   1.496308      1.041280    0.933897  0.565130     -1.837804    70   \n",
       "5    15.0   1.496308      2.259274    2.451322  1.618455     -2.019115    70   \n",
       "6    14.0   1.496308      2.499036    3.026898  1.633806     -2.381737    70   \n",
       "7    14.0   1.496308      2.364769    2.896085  1.584210     -2.563048    70   \n",
       "8    14.0   1.496308      2.508627    3.157710  1.717647     -2.019115    70   \n",
       "9    15.0   1.496308      1.885244    2.242022  1.038654     -2.563048    70   \n",
       "10   15.0   1.496308      1.818111    1.718772  0.699747     -2.019115    70   \n",
       "11   14.0   1.496308      1.405719    1.457147  0.754067     -2.744360    70   \n",
       "12   15.0   1.496308      1.981149    1.195522  0.933557     -2.200426    70   \n",
       "13   14.0   1.496308      2.508627    3.157710  0.136478     -2.019115    70   \n",
       "14   24.0  -0.855244     -0.771324   -0.243417 -0.706655     -0.206002    70   \n",
       "15   22.0   0.320532      0.043868   -0.243417 -0.162279     -0.024691    70   \n",
       "16   18.0   0.320532      0.053459   -0.191092 -0.231950     -0.024691    70   \n",
       "17   21.0   0.320532      0.063049   -0.505042 -0.452770      0.156620    70   \n",
       "18   27.0  -0.855244     -0.924773   -0.426554 -0.992422     -0.387314    70   \n",
       "19   26.0  -0.855244     -0.924773   -1.525380 -1.340775      1.788421    70   \n",
       "20   25.0  -0.855244     -0.800096   -0.452717 -0.352397      0.700554    70   \n",
       "21   24.0  -0.855244     -0.828867   -0.374229 -0.638165     -0.387314    70   \n",
       "22   25.0  -0.855244     -0.857639   -0.243417 -0.703112      0.700554    70   \n",
       "23   26.0  -0.855244     -0.694600    0.227509 -0.869613     -1.112559    70   \n",
       "24   21.0   0.320532      0.053459   -0.374229 -0.380738     -0.206002    70   \n",
       "25   10.0   1.496308      1.597529    2.896085  1.942010     -0.568625    70   \n",
       "26   10.0   1.496308      1.089233    2.503648  1.659785     -0.206002    70   \n",
       "27   11.0   1.496308      1.194728    2.765273  1.666870     -0.749936    70   \n",
       "28    9.0   1.496308      1.060461    2.320510  2.080171      1.063176    70   \n",
       "29   27.0  -0.855244     -0.924773   -0.426554 -0.992422     -0.387314    71   \n",
       "..    ...        ...           ...         ...       ...           ...   ...   \n",
       "368  27.0  -0.855244     -0.780915   -0.426554 -0.390185      1.099439    82   \n",
       "369  34.0  -0.855244     -0.780915   -0.426554 -0.679495      0.881865    82   \n",
       "370  31.0  -0.855244     -0.780915   -0.505042 -0.466940      0.229145    82   \n",
       "371  29.0  -0.855244     -0.560333   -0.531204 -0.525983      0.156620    82   \n",
       "372  27.0  -0.855244     -0.406885   -0.374229 -0.278003      0.881865    82   \n",
       "373  24.0  -0.855244     -0.512381   -0.321904 -0.124492      0.301669    82   \n",
       "374  23.0  -0.855244     -0.406885   -0.282660  0.076254      1.788421    82   \n",
       "375  36.0  -0.855244     -0.848048   -0.792829 -1.169551     -0.097216    82   \n",
       "376  37.0  -0.855244     -0.982316   -0.949804 -1.116412      0.954390    82   \n",
       "377  31.0  -0.855244     -0.982316   -0.949804 -1.181360      0.736816    82   \n",
       "378  38.0  -0.855244     -0.848048   -1.080617 -0.998327     -0.314789    82   \n",
       "379  36.0  -0.855244     -0.915182   -0.897479 -0.998327      0.628029    82   \n",
       "380  36.0  -0.855244     -0.704191   -0.426554 -0.956997     -0.387314    82   \n",
       "381  36.0  -0.855244     -0.828867   -0.766667 -0.903858     -0.387314    82   \n",
       "382  34.0  -0.855244     -0.819277   -0.897479 -0.856624      0.482980    82   \n",
       "383  38.0  -0.855244     -0.982316   -0.975967 -1.187264     -0.206002    82   \n",
       "384  32.0  -0.855244     -0.982316   -0.975967 -1.187264      0.047833    82   \n",
       "385  38.0  -0.855244     -0.982316   -0.975967 -1.151838      0.229145    82   \n",
       "386  25.0   0.320532     -0.119170    0.149021 -0.030023      0.301669    82   \n",
       "387  38.0   0.320532      0.657660   -0.505042  0.052637      0.519243    82   \n",
       "388  26.0  -0.855244     -0.358933   -0.321904 -0.455132     -0.387314    82   \n",
       "389  22.0   0.320532      0.369945    0.201346 -0.159917     -0.314789    82   \n",
       "390  32.0  -0.855244     -0.474019   -0.217254 -0.360663     -0.604887    82   \n",
       "391  36.0  -0.855244     -0.560333   -0.531204 -0.709016     -0.931247    82   \n",
       "392  27.0  -0.855244     -0.406885   -0.374229 -0.024119      0.628029    82   \n",
       "393  27.0  -0.855244     -0.512381   -0.478879 -0.213056      0.011571    82   \n",
       "394  44.0  -0.855244     -0.924773   -1.368405 -0.992422      3.275173    82   \n",
       "395  32.0  -0.855244     -0.560333   -0.531204 -0.797581     -1.438919    82   \n",
       "396  28.0  -0.855244     -0.704191   -0.662017 -0.407897      1.099439    82   \n",
       "397  31.0  -0.855244     -0.713781   -0.583529 -0.295716      1.389537    82   \n",
       "\n",
       "     origin-1  origin-2  origin-3       pred  ideal  \n",
       "0           1         0         0  17.913458   18.0  \n",
       "1           1         0         0  14.878858   15.0  \n",
       "2           1         0         0  17.878546   18.0  \n",
       "3           1         0         0  15.882986   16.0  \n",
       "4           1         0         0  16.907516   17.0  \n",
       "5           1         0         0  14.791887   15.0  \n",
       "6           1         0         0  13.774524   14.0  \n",
       "7           1         0         0  13.781412   14.0  \n",
       "8           1         0         0  13.739818   14.0  \n",
       "9           1         0         0  14.849905   15.0  \n",
       "10          1         0         0  14.942660   15.0  \n",
       "11          1         0         0  13.937535   14.0  \n",
       "12          1         0         0  15.010536   15.0  \n",
       "13          1         0         0  13.949841   14.0  \n",
       "14          0         0         1  23.798086   24.0  \n",
       "15          1         0         0  21.855574   22.0  \n",
       "16          1         0         0  17.903589   18.0  \n",
       "17          1         0         0  20.940790   21.0  \n",
       "18          0         0         1  26.814463   27.0  \n",
       "19          0         1         0  25.975174   26.0  \n",
       "20          0         1         0  24.749441   25.0  \n",
       "21          0         1         0  23.818041   24.0  \n",
       "22          0         1         0  24.765955   25.0  \n",
       "23          0         1         0  25.792355   26.0  \n",
       "24          1         0         0  20.921858   21.0  \n",
       "25          1         0         0  10.124063   10.0  \n",
       "26          1         0         0  10.234016   10.0  \n",
       "27          1         0         0  10.845525   11.0  \n",
       "28          1         0         0   9.491858    9.0  \n",
       "29          0         0         1  26.818274   27.0  \n",
       "..        ...       ...       ...        ...    ...  \n",
       "368         1         0         0  26.714170   27.0  \n",
       "369         1         0         0  33.687473   34.0  \n",
       "370         1         0         0  30.716448   31.0  \n",
       "371         1         0         0  28.783884   29.0  \n",
       "372         1         0         0  26.750744   27.0  \n",
       "373         1         0         0  23.754368   24.0  \n",
       "374         1         0         0  22.704788   23.0  \n",
       "375         0         1         0  35.856297   36.0  \n",
       "376         0         0         1  36.793159   37.0  \n",
       "377         0         0         1  30.873365   31.0  \n",
       "378         1         0         0  37.799049   38.0  \n",
       "379         1         0         0  35.761387   36.0  \n",
       "380         0         0         1  35.789833   36.0  \n",
       "381         0         0         1  35.807884   36.0  \n",
       "382         0         0         1  33.816803   34.0  \n",
       "383         0         0         1  37.828106   38.0  \n",
       "384         0         0         1  31.885767   32.0  \n",
       "385         0         0         1  37.810921   38.0  \n",
       "386         1         0         0  24.766397   25.0  \n",
       "387         1         0         0  37.804516   38.0  \n",
       "388         1         0         0  25.822718   26.0  \n",
       "389         1         0         0  21.898605   22.0  \n",
       "390         0         0         1  31.756998   32.0  \n",
       "391         1         0         0  35.765396   36.0  \n",
       "392         1         0         0  26.720211   27.0  \n",
       "393         1         0         0  26.763346   27.0  \n",
       "394         0         1         0  43.714481   44.0  \n",
       "395         1         0         0  31.835516   32.0  \n",
       "396         1         0         0  27.747446   28.0  \n",
       "397         1         0         0  30.679079   31.0  \n",
       "\n",
       "[398 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as skflow\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "missing_median(df, 'horsepower')\n",
    "df.drop('name',1,inplace=True)\n",
    "encode_numeric_zscore(df, 'horsepower')\n",
    "encode_numeric_zscore(df, 'weight')\n",
    "encode_numeric_zscore(df, 'cylinders')\n",
    "encode_numeric_zscore(df, 'displacement')\n",
    "encode_numeric_zscore(df, 'acceleration')\n",
    "encode_text_dummy(df, 'origin')\n",
    "\n",
    "df\n",
    "\n",
    "x,y = to_xy(df,['mpg'])\n",
    "\n",
    "model_dir = 'tmp/mpg1' \n",
    "\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "regressor = skflow.DNNRegressor(\n",
    "    model_dir= model_dir,\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[50, 25, 10])\n",
    "\n",
    "regressor.fit(x, y,steps=1000)\n",
    "\n",
    "pred = list(regressor.predict(x, as_iterable=True))\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n",
    "pred = list(regressor.predict(x, as_iterable=True))\n",
    "predDF = pd.DataFrame(pred)\n",
    "df2 = pd.concat([df,predDF,pd.DataFrame(y)],axis=1)\n",
    "\n",
    "df2.columns = list(df.columns)+['pred','ideal']\n",
    "df2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNNRegressor(feature_columns=[_RealValuedColumn(column_name='', dimension=398, default_value=None, dtype=tf.float32, normalizer=None)], optimizer=None, dropout=None, hidden_units=[50, 25, 10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.contrib.learn as learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "missing_median(df, 'horsepower')\n",
    "df.drop('name',1,inplace=True)\n",
    "encode_numeric_zscore(df, 'horsepower')\n",
    "encode_numeric_zscore(df, 'weight')\n",
    "encode_numeric_zscore(df, 'cylinders')\n",
    "encode_numeric_zscore(df, 'displacement')\n",
    "encode_numeric_zscore(df, 'acceleration')\n",
    "encode_text_dummy(df, 'origin')\n",
    "\n",
    "x,y = to_xy(df,'mpg')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "model_dir = 'tmp/mpg2' \n",
    "\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "regressor = learn.DNNRegressor(\n",
    "    model_dir= model_dir,\n",
    "    config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1),\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[50, 25, 10])\n",
    "\n",
    "validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    every_n_steps=500,\n",
    "    early_stopping_metric=\"loss\",\n",
    "    early_stopping_metric_minimize=True,\n",
    "    early_stopping_rounds=50)\n",
    "    \n",
    "regressor.fit(x_train, y_train,monitors=[validation_monitor],steps=10000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (MSE): 5.466667175292969\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "pred = list(regressor.predict(x_test, as_iterable=True))\n",
    "\n",
    "score = metrics.mean_squared_error(pred,y_test)\n",
    "print(\"Final score (MSE): {}\".format(score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 2.338090419769287\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Final score (RMSE): {}\".format(score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Fold score (RMSE): 2.7842540740966797\n",
      "Fold #2\n",
      "Fold score (RMSE): 3.394286870956421\n",
      "Fold #3\n",
      "Fold score (RMSE): 3.275982618331909\n",
      "Fold #4\n",
      "Fold score (RMSE): 3.941182851791382\n",
      "Fold #5\n",
      "Fold score (RMSE): 3.4482271671295166\n",
      "Final, out of sample score (RMSE): 3.3874053955078125\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.contrib.learn as learn\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
    "filename_write = os.path.join(path,\"auto-mpg-out-of-sample.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "missing_median(df, 'horsepower')\n",
    "df.drop('name',1,inplace=True)\n",
    "encode_numeric_zscore(df, 'horsepower')\n",
    "encode_numeric_zscore(df, 'weight')\n",
    "encode_numeric_zscore(df, 'cylinders')\n",
    "encode_numeric_zscore(df, 'displacement')\n",
    "encode_numeric_zscore(df, 'acceleration')\n",
    "encode_text_dummy(df, 'origin')\n",
    "\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "x,y = to_xy(df,'mpg')\n",
    "\n",
    "kf = KFold(5)\n",
    "    \n",
    "all_y = []\n",
    "all_pred = []\n",
    "fold = 0\n",
    "for train, test in kf.split(x):\n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    model_dir = 'tmp/mpgKF' + str(fold)\n",
    "\n",
    "    feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "    regressor = learn.DNNRegressor(\n",
    "        model_dir= model_dir,\n",
    "        config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1),\n",
    "        feature_columns=feature_columns,\n",
    "        hidden_units=[50, 25, 10])\n",
    "\n",
    "    validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "        x_test,\n",
    "        y_test,\n",
    "        every_n_steps=50,\n",
    "        early_stopping_metric=\"loss\",\n",
    "        early_stopping_metric_minimize=True,\n",
    "        early_stopping_rounds=50)\n",
    "    \n",
    "    regressor.fit(x_train, y_train,monitors=[validation_monitor],steps=10000)\n",
    "\n",
    "    pred = list(regressor.predict(x_test, as_iterable=True))\n",
    "    \n",
    "    all_y.append(y_test)\n",
    "    all_pred.append(pred)        \n",
    "\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "\n",
    "all_y = np.concatenate(all_y)\n",
    "all_pred = np.concatenate(all_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(all_pred,all_y))\n",
    "print(\"Final, out of sample score (RMSE): {}\".format(score))    \n",
    "    \n",
    "all_y = pd.DataFrame(all_y)\n",
    "all_pred = pd.DataFrame(all_pred)\n",
    "allDF = pd.concat( [df, all_y, all_pred],axis=1 )\n",
    "allDF.to_csv(filename_write,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Fold score (RMSE): 3.7783710956573486\n",
      "Fold #2\n",
      "Fold score (RMSE): 3.3557262420654297\n",
      "Fold #3\n",
      "Fold score (RMSE): 3.524622678756714\n",
      "Fold #4\n",
      "Fold score (RMSE): 3.0937066078186035\n",
      "Fold #5\n",
      "Fold score (RMSE): 3.7664620876312256\n",
      "\n",
      "Cross-validated score (RMSE): 3.51369309425354\n",
      "Holdout score (RMSE): 2.8932342529296875\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.contrib.learn as learn\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
    "filename_write = os.path.join(path,\"auto-mpg-holdout.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "missing_median(df, 'horsepower')\n",
    "df.drop('name',1,inplace=True)\n",
    "encode_numeric_zscore(df, 'horsepower')\n",
    "encode_numeric_zscore(df, 'weight')\n",
    "encode_numeric_zscore(df, 'cylinders')\n",
    "encode_numeric_zscore(df, 'displacement')\n",
    "encode_numeric_zscore(df, 'acceleration')\n",
    "encode_text_dummy(df, 'origin')\n",
    "\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "x,y = to_xy(df,'mpg')\n",
    "\n",
    "x_main, x_holdout, y_main, y_holdout = train_test_split(    \n",
    "    x, y, test_size=0.10) \n",
    "\n",
    "kf = KFold(5)\n",
    "    \n",
    "all_y = []\n",
    "all_pred = []\n",
    "fold = 0\n",
    "for train, test in kf.split(x_main):        \n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train = x_main[train]\n",
    "    y_train = y_main[train]\n",
    "    x_test = x_main[test]\n",
    "    y_test = y_main[test]\n",
    "    \n",
    "    model_dir = 'tmp/mpgKFHS' + str(fold)\n",
    "\n",
    "    feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "    regressor = learn.DNNRegressor(\n",
    "        model_dir= model_dir,\n",
    "        config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1),\n",
    "        feature_columns=feature_columns,\n",
    "        hidden_units=[50, 25, 10])\n",
    "\n",
    "    validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "        x_test,\n",
    "        y_test,\n",
    "        every_n_steps=50,\n",
    "        early_stopping_metric=\"loss\",\n",
    "        early_stopping_metric_minimize=True,\n",
    "        early_stopping_rounds=50)\n",
    "    \n",
    "    regressor.fit(x_train, y_train,monitors=[validation_monitor],steps=10000)\n",
    "\n",
    "    pred = list(regressor.predict(x_test, as_iterable=True))\n",
    "    \n",
    "    all_y.append(y_test)\n",
    "    all_pred.append(pred)        \n",
    "\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "all_y = np.concatenate(all_y)\n",
    "all_pred = np.concatenate(all_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(all_pred,all_y))\n",
    "print()\n",
    "print(\"Cross-validated score (RMSE): {}\".format(score))    \n",
    "    \n",
    "holdout_pred = list(regressor.predict(x_holdout, as_iterable=True))\n",
    "\n",
    "score = np.sqrt(metrics.mean_squared_error(holdout_pred,y_holdout))\n",
    "print(\"Holdout score (RMSE): {}\".format(score))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chart_regression(pred,y):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y_test.flatten()})\n",
    "    t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (RMSE): 2.9808456897735596\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHj8NRGL/gAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11de9bdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "import tensorflow.contrib.learn as learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "filename_read = os.path.join(path,\"auto-mpg.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "missing_median(df, 'horsepower')\n",
    "df.drop('name',1,inplace=True)\n",
    "encode_numeric_zscore(df, 'horsepower')\n",
    "encode_numeric_zscore(df, 'weight')\n",
    "encode_numeric_zscore(df, 'cylinders')\n",
    "encode_numeric_zscore(df, 'displacement')\n",
    "encode_numeric_zscore(df, 'acceleration')\n",
    "encode_text_dummy(df, 'origin')\n",
    "\n",
    "x,y = to_xy(df,'mpg')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.20, random_state=42)\n",
    "\n",
    "model_dir = 'tmp/mpg3' \n",
    "\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "regressor = learn.DNNRegressor(\n",
    "    model_dir= model_dir,\n",
    "    config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1),\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[50,25,10])\n",
    "\n",
    "validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    every_n_steps=100,\n",
    "    early_stopping_metric=\"loss\",\n",
    "    early_stopping_metric_minimize=True,\n",
    "    early_stopping_rounds=100)\n",
    "    \n",
    "regressor.fit(x_train, y_train,monitors=[validation_monitor],batch_size=32,steps=10000)\n",
    "\n",
    "pred = list(regressor.predict(x_test, as_iterable=True))\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Score (RMSE): {}\".format(score))\n",
    "\n",
    "chart_regression(pred,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
