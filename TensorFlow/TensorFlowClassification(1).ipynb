{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_text_index(df,name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "def encode_numeric_zscore(df,name,mean=None,sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name]-mean)/sd\n",
    "    \n",
    "def to_xy(df,target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    \n",
    "    if target_type in (np.int64, np.int32):\n",
    "        return df.as_matrix(result).astype(np.float32),df.as_matrix([target]).astype(np.int32)\n",
    "    else:\n",
    "        return df.as_matrix(result).astype(np.float32),df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score: 0.9866666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_l</th>\n",
       "      <th>sepal_w</th>\n",
       "      <th>petal_l</th>\n",
       "      <th>petal_w</th>\n",
       "      <th>expected</th>\n",
       "      <th>predicted</th>\n",
       "      <th>expected_str</th>\n",
       "      <th>predicted_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.897674</td>\n",
       "      <td>1.015602</td>\n",
       "      <td>-1.335752</td>\n",
       "      <td>-1.311052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.139200</td>\n",
       "      <td>-0.131539</td>\n",
       "      <td>-1.335752</td>\n",
       "      <td>-1.311052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.380727</td>\n",
       "      <td>0.327318</td>\n",
       "      <td>-1.392399</td>\n",
       "      <td>-1.311052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.501490</td>\n",
       "      <td>0.097889</td>\n",
       "      <td>-1.279104</td>\n",
       "      <td>-1.311052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.018437</td>\n",
       "      <td>1.245030</td>\n",
       "      <td>-1.335752</td>\n",
       "      <td>-1.311052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.535384</td>\n",
       "      <td>1.933315</td>\n",
       "      <td>-1.165809</td>\n",
       "      <td>-1.048667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.501490</td>\n",
       "      <td>0.786174</td>\n",
       "      <td>-1.335752</td>\n",
       "      <td>-1.179859</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.018437</td>\n",
       "      <td>0.786174</td>\n",
       "      <td>-1.279104</td>\n",
       "      <td>-1.311052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.743017</td>\n",
       "      <td>-0.360967</td>\n",
       "      <td>-1.335752</td>\n",
       "      <td>-1.311052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.139200</td>\n",
       "      <td>0.097889</td>\n",
       "      <td>-1.279104</td>\n",
       "      <td>-1.442245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.535384</td>\n",
       "      <td>1.474458</td>\n",
       "      <td>-1.279104</td>\n",
       "      <td>-1.311052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.259964</td>\n",
       "      <td>0.786174</td>\n",
       "      <td>-1.222456</td>\n",
       "      <td>-1.311052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.259964</td>\n",
       "      <td>-0.131539</td>\n",
       "      <td>-1.335752</td>\n",
       "      <td>-1.442245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.863780</td>\n",
       "      <td>-0.131539</td>\n",
       "      <td>-1.505695</td>\n",
       "      <td>-1.442245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.052331</td>\n",
       "      <td>2.162743</td>\n",
       "      <td>-1.449047</td>\n",
       "      <td>-1.311052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.173094</td>\n",
       "      <td>3.080455</td>\n",
       "      <td>-1.279104</td>\n",
       "      <td>-1.048667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.535384</td>\n",
       "      <td>1.933315</td>\n",
       "      <td>-1.392399</td>\n",
       "      <td>-1.048667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.897674</td>\n",
       "      <td>1.015602</td>\n",
       "      <td>-1.335752</td>\n",
       "      <td>-1.179859</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.173094</td>\n",
       "      <td>1.703886</td>\n",
       "      <td>-1.165809</td>\n",
       "      <td>-1.179859</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.897674</td>\n",
       "      <td>1.703886</td>\n",
       "      <td>-1.279104</td>\n",
       "      <td>-1.179859</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.535384</td>\n",
       "      <td>0.786174</td>\n",
       "      <td>-1.165809</td>\n",
       "      <td>-1.311052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.897674</td>\n",
       "      <td>1.474458</td>\n",
       "      <td>-1.279104</td>\n",
       "      <td>-1.048667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.501490</td>\n",
       "      <td>1.245030</td>\n",
       "      <td>-1.562342</td>\n",
       "      <td>-1.311052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.897674</td>\n",
       "      <td>0.556746</td>\n",
       "      <td>-1.165809</td>\n",
       "      <td>-0.917474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1.259964</td>\n",
       "      <td>0.786174</td>\n",
       "      <td>-1.052513</td>\n",
       "      <td>-1.311052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.018437</td>\n",
       "      <td>-0.131539</td>\n",
       "      <td>-1.222456</td>\n",
       "      <td>-1.311052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-1.018437</td>\n",
       "      <td>0.786174</td>\n",
       "      <td>-1.222456</td>\n",
       "      <td>-1.048667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.776911</td>\n",
       "      <td>1.015602</td>\n",
       "      <td>-1.279104</td>\n",
       "      <td>-1.311052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.776911</td>\n",
       "      <td>0.786174</td>\n",
       "      <td>-1.335752</td>\n",
       "      <td>-1.311052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1.380727</td>\n",
       "      <td>0.327318</td>\n",
       "      <td>-1.222456</td>\n",
       "      <td>-1.311052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1.276066</td>\n",
       "      <td>0.327318</td>\n",
       "      <td>1.100097</td>\n",
       "      <td>1.443994</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>-0.293857</td>\n",
       "      <td>-0.590395</td>\n",
       "      <td>0.646916</td>\n",
       "      <td>1.050416</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2.242172</td>\n",
       "      <td>-0.590395</td>\n",
       "      <td>1.666574</td>\n",
       "      <td>1.050416</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.551486</td>\n",
       "      <td>-0.819823</td>\n",
       "      <td>0.646916</td>\n",
       "      <td>0.788031</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1.034539</td>\n",
       "      <td>0.556746</td>\n",
       "      <td>1.100097</td>\n",
       "      <td>1.181609</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1.638355</td>\n",
       "      <td>0.327318</td>\n",
       "      <td>1.270040</td>\n",
       "      <td>0.788031</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.430722</td>\n",
       "      <td>-0.590395</td>\n",
       "      <td>0.590269</td>\n",
       "      <td>0.788031</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.309959</td>\n",
       "      <td>-0.131539</td>\n",
       "      <td>0.646916</td>\n",
       "      <td>0.788031</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.672249</td>\n",
       "      <td>-0.590395</td>\n",
       "      <td>1.043450</td>\n",
       "      <td>1.181609</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1.638355</td>\n",
       "      <td>-0.131539</td>\n",
       "      <td>1.156745</td>\n",
       "      <td>0.525645</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1.879882</td>\n",
       "      <td>-0.590395</td>\n",
       "      <td>1.326688</td>\n",
       "      <td>0.919223</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2.483699</td>\n",
       "      <td>1.703886</td>\n",
       "      <td>1.496631</td>\n",
       "      <td>1.050416</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.672249</td>\n",
       "      <td>-0.590395</td>\n",
       "      <td>1.043450</td>\n",
       "      <td>1.312801</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.551486</td>\n",
       "      <td>-0.590395</td>\n",
       "      <td>0.760211</td>\n",
       "      <td>0.394453</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.309959</td>\n",
       "      <td>-1.049251</td>\n",
       "      <td>1.043450</td>\n",
       "      <td>0.263260</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2.242172</td>\n",
       "      <td>-0.131539</td>\n",
       "      <td>1.326688</td>\n",
       "      <td>1.443994</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.551486</td>\n",
       "      <td>0.786174</td>\n",
       "      <td>1.043450</td>\n",
       "      <td>1.575187</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.672249</td>\n",
       "      <td>0.097889</td>\n",
       "      <td>0.986802</td>\n",
       "      <td>0.788031</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.189196</td>\n",
       "      <td>-0.131539</td>\n",
       "      <td>0.590269</td>\n",
       "      <td>0.788031</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1.276066</td>\n",
       "      <td>0.097889</td>\n",
       "      <td>0.930154</td>\n",
       "      <td>1.181609</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1.034539</td>\n",
       "      <td>0.097889</td>\n",
       "      <td>1.043450</td>\n",
       "      <td>1.575187</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1.276066</td>\n",
       "      <td>0.097889</td>\n",
       "      <td>0.760211</td>\n",
       "      <td>1.443994</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>-0.052331</td>\n",
       "      <td>-0.819823</td>\n",
       "      <td>0.760211</td>\n",
       "      <td>0.919223</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1.155302</td>\n",
       "      <td>0.327318</td>\n",
       "      <td>1.213393</td>\n",
       "      <td>1.443994</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1.034539</td>\n",
       "      <td>0.556746</td>\n",
       "      <td>1.100097</td>\n",
       "      <td>1.706379</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1.034539</td>\n",
       "      <td>-0.131539</td>\n",
       "      <td>0.816859</td>\n",
       "      <td>1.443994</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.551486</td>\n",
       "      <td>-1.278680</td>\n",
       "      <td>0.703564</td>\n",
       "      <td>0.919223</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.793012</td>\n",
       "      <td>-0.131539</td>\n",
       "      <td>0.816859</td>\n",
       "      <td>1.050416</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.430722</td>\n",
       "      <td>0.786174</td>\n",
       "      <td>0.930154</td>\n",
       "      <td>1.443994</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.068433</td>\n",
       "      <td>-0.131539</td>\n",
       "      <td>0.760211</td>\n",
       "      <td>0.788031</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sepal_l   sepal_w   petal_l   petal_w  expected  predicted  \\\n",
       "0   -0.897674  1.015602 -1.335752 -1.311052         0          0   \n",
       "1   -1.139200 -0.131539 -1.335752 -1.311052         0          0   \n",
       "2   -1.380727  0.327318 -1.392399 -1.311052         0          0   \n",
       "3   -1.501490  0.097889 -1.279104 -1.311052         0          0   \n",
       "4   -1.018437  1.245030 -1.335752 -1.311052         0          0   \n",
       "5   -0.535384  1.933315 -1.165809 -1.048667         0          0   \n",
       "6   -1.501490  0.786174 -1.335752 -1.179859         0          0   \n",
       "7   -1.018437  0.786174 -1.279104 -1.311052         0          0   \n",
       "8   -1.743017 -0.360967 -1.335752 -1.311052         0          0   \n",
       "9   -1.139200  0.097889 -1.279104 -1.442245         0          0   \n",
       "10  -0.535384  1.474458 -1.279104 -1.311052         0          0   \n",
       "11  -1.259964  0.786174 -1.222456 -1.311052         0          0   \n",
       "12  -1.259964 -0.131539 -1.335752 -1.442245         0          0   \n",
       "13  -1.863780 -0.131539 -1.505695 -1.442245         0          0   \n",
       "14  -0.052331  2.162743 -1.449047 -1.311052         0          0   \n",
       "15  -0.173094  3.080455 -1.279104 -1.048667         0          0   \n",
       "16  -0.535384  1.933315 -1.392399 -1.048667         0          0   \n",
       "17  -0.897674  1.015602 -1.335752 -1.179859         0          0   \n",
       "18  -0.173094  1.703886 -1.165809 -1.179859         0          0   \n",
       "19  -0.897674  1.703886 -1.279104 -1.179859         0          0   \n",
       "20  -0.535384  0.786174 -1.165809 -1.311052         0          0   \n",
       "21  -0.897674  1.474458 -1.279104 -1.048667         0          0   \n",
       "22  -1.501490  1.245030 -1.562342 -1.311052         0          0   \n",
       "23  -0.897674  0.556746 -1.165809 -0.917474         0          0   \n",
       "24  -1.259964  0.786174 -1.052513 -1.311052         0          0   \n",
       "25  -1.018437 -0.131539 -1.222456 -1.311052         0          0   \n",
       "26  -1.018437  0.786174 -1.222456 -1.048667         0          0   \n",
       "27  -0.776911  1.015602 -1.279104 -1.311052         0          0   \n",
       "28  -0.776911  0.786174 -1.335752 -1.311052         0          0   \n",
       "29  -1.380727  0.327318 -1.222456 -1.311052         0          0   \n",
       "..        ...       ...       ...       ...       ...        ...   \n",
       "120  1.276066  0.327318  1.100097  1.443994         2          2   \n",
       "121 -0.293857 -0.590395  0.646916  1.050416         2          2   \n",
       "122  2.242172 -0.590395  1.666574  1.050416         2          2   \n",
       "123  0.551486 -0.819823  0.646916  0.788031         2          2   \n",
       "124  1.034539  0.556746  1.100097  1.181609         2          2   \n",
       "125  1.638355  0.327318  1.270040  0.788031         2          2   \n",
       "126  0.430722 -0.590395  0.590269  0.788031         2          2   \n",
       "127  0.309959 -0.131539  0.646916  0.788031         2          2   \n",
       "128  0.672249 -0.590395  1.043450  1.181609         2          2   \n",
       "129  1.638355 -0.131539  1.156745  0.525645         2          2   \n",
       "130  1.879882 -0.590395  1.326688  0.919223         2          2   \n",
       "131  2.483699  1.703886  1.496631  1.050416         2          2   \n",
       "132  0.672249 -0.590395  1.043450  1.312801         2          2   \n",
       "133  0.551486 -0.590395  0.760211  0.394453         2          1   \n",
       "134  0.309959 -1.049251  1.043450  0.263260         2          2   \n",
       "135  2.242172 -0.131539  1.326688  1.443994         2          2   \n",
       "136  0.551486  0.786174  1.043450  1.575187         2          2   \n",
       "137  0.672249  0.097889  0.986802  0.788031         2          2   \n",
       "138  0.189196 -0.131539  0.590269  0.788031         2          2   \n",
       "139  1.276066  0.097889  0.930154  1.181609         2          2   \n",
       "140  1.034539  0.097889  1.043450  1.575187         2          2   \n",
       "141  1.276066  0.097889  0.760211  1.443994         2          2   \n",
       "142 -0.052331 -0.819823  0.760211  0.919223         2          2   \n",
       "143  1.155302  0.327318  1.213393  1.443994         2          2   \n",
       "144  1.034539  0.556746  1.100097  1.706379         2          2   \n",
       "145  1.034539 -0.131539  0.816859  1.443994         2          2   \n",
       "146  0.551486 -1.278680  0.703564  0.919223         2          2   \n",
       "147  0.793012 -0.131539  0.816859  1.050416         2          2   \n",
       "148  0.430722  0.786174  0.930154  1.443994         2          2   \n",
       "149  0.068433 -0.131539  0.760211  0.788031         2          2   \n",
       "\n",
       "        expected_str   predicted_str  \n",
       "0        Iris-setosa     Iris-setosa  \n",
       "1        Iris-setosa     Iris-setosa  \n",
       "2        Iris-setosa     Iris-setosa  \n",
       "3        Iris-setosa     Iris-setosa  \n",
       "4        Iris-setosa     Iris-setosa  \n",
       "5        Iris-setosa     Iris-setosa  \n",
       "6        Iris-setosa     Iris-setosa  \n",
       "7        Iris-setosa     Iris-setosa  \n",
       "8        Iris-setosa     Iris-setosa  \n",
       "9        Iris-setosa     Iris-setosa  \n",
       "10       Iris-setosa     Iris-setosa  \n",
       "11       Iris-setosa     Iris-setosa  \n",
       "12       Iris-setosa     Iris-setosa  \n",
       "13       Iris-setosa     Iris-setosa  \n",
       "14       Iris-setosa     Iris-setosa  \n",
       "15       Iris-setosa     Iris-setosa  \n",
       "16       Iris-setosa     Iris-setosa  \n",
       "17       Iris-setosa     Iris-setosa  \n",
       "18       Iris-setosa     Iris-setosa  \n",
       "19       Iris-setosa     Iris-setosa  \n",
       "20       Iris-setosa     Iris-setosa  \n",
       "21       Iris-setosa     Iris-setosa  \n",
       "22       Iris-setosa     Iris-setosa  \n",
       "23       Iris-setosa     Iris-setosa  \n",
       "24       Iris-setosa     Iris-setosa  \n",
       "25       Iris-setosa     Iris-setosa  \n",
       "26       Iris-setosa     Iris-setosa  \n",
       "27       Iris-setosa     Iris-setosa  \n",
       "28       Iris-setosa     Iris-setosa  \n",
       "29       Iris-setosa     Iris-setosa  \n",
       "..               ...             ...  \n",
       "120   Iris-virginica  Iris-virginica  \n",
       "121   Iris-virginica  Iris-virginica  \n",
       "122   Iris-virginica  Iris-virginica  \n",
       "123   Iris-virginica  Iris-virginica  \n",
       "124   Iris-virginica  Iris-virginica  \n",
       "125   Iris-virginica  Iris-virginica  \n",
       "126   Iris-virginica  Iris-virginica  \n",
       "127   Iris-virginica  Iris-virginica  \n",
       "128   Iris-virginica  Iris-virginica  \n",
       "129   Iris-virginica  Iris-virginica  \n",
       "130   Iris-virginica  Iris-virginica  \n",
       "131   Iris-virginica  Iris-virginica  \n",
       "132   Iris-virginica  Iris-virginica  \n",
       "133  Iris-versicolor  Iris-virginica  \n",
       "134   Iris-virginica  Iris-virginica  \n",
       "135   Iris-virginica  Iris-virginica  \n",
       "136   Iris-virginica  Iris-virginica  \n",
       "137   Iris-virginica  Iris-virginica  \n",
       "138   Iris-virginica  Iris-virginica  \n",
       "139   Iris-virginica  Iris-virginica  \n",
       "140   Iris-virginica  Iris-virginica  \n",
       "141   Iris-virginica  Iris-virginica  \n",
       "142   Iris-virginica  Iris-virginica  \n",
       "143   Iris-virginica  Iris-virginica  \n",
       "144   Iris-virginica  Iris-virginica  \n",
       "145   Iris-virginica  Iris-virginica  \n",
       "146   Iris-virginica  Iris-virginica  \n",
       "147   Iris-virginica  Iris-virginica  \n",
       "148   Iris-virginica  Iris-virginica  \n",
       "149   Iris-virginica  Iris-virginica  \n",
       "\n",
       "[150 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as learn\n",
    "from sklearn import metrics\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "filename_read = os.path.join(path,\"iris.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "encode_numeric_zscore(df,'sepal_l')\n",
    "encode_numeric_zscore(df,'sepal_w')\n",
    "encode_numeric_zscore(df,'petal_l')\n",
    "encode_numeric_zscore(df,'petal_w')\n",
    "species = encode_text_index(df,'species')\n",
    "num_classes = len(species)\n",
    "\n",
    "x,y = to_xy(df,'species')\n",
    "\n",
    "model_dir = 'tmp/iris' \n",
    "\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "classifier = learn.DNNClassifier(\n",
    "    model_dir= model_dir,\n",
    "    hidden_units=[10, 20, 5], n_classes=num_classes, feature_columns=feature_columns)\n",
    "\n",
    "classifier.fit(x, y, steps=1000)\n",
    "\n",
    "pred = list(classifier.predict(x, as_iterable=True))\n",
    "score = metrics.accuracy_score(y, pred)\n",
    "print(\"Final score: {}\".format(score))\n",
    "\n",
    "pred = list(classifier.predict(x, as_iterable=True))\n",
    "predDF = pd.DataFrame(pred)\n",
    "pred_nameDF = pd.DataFrame(species[pred])\n",
    "actual_nameDF = pd.DataFrame(species[df['species']])\n",
    "\n",
    "df2 = pd.concat([df,predDF,pred_nameDF,actual_nameDF],axis=1)\n",
    "df2.columns = ['sepal_l','sepal_w','petal_l','petal_w','expected','predicted','expected_str','predicted_str']\n",
    "\n",
    "df2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ad hoc prediction - Predict that [[ 5.  3.  4.  2.]] is: ['Iris-virginica']\n",
      "Two sample flower predictions - Predict that [[ 5.   3.   4.   2. ]\n",
      " [ 5.2  3.5  1.5  0.8]] is: ['Iris-virginica' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "sample_flower = np.array( [[5.0,3.0,4.0,2.0]], dtype=float)\n",
    "pred = list(classifier.predict(sample_flower, as_iterable=True))\n",
    "print(\"Ad hoc prediction - Predict that {} is: {}\".format(sample_flower,species[pred]))\n",
    "\n",
    "sample_flower = np.array( [[5.0,3.0,4.0,2.0],[5.2,3.5,1.5,0.8]], dtype=float)\n",
    "pred = list(classifier.predict(sample_flower, as_iterable=True))\n",
    "print(\"Two sample flower predictions - Predict that {} is: {}\".format(sample_flower,species[pred]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy before save: 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as learn\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "path = \"./data/\"\n",
    "\n",
    "filename_read = os.path.join(path,\"iris.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "encode_numeric_zscore(df,'sepal_l')\n",
    "encode_numeric_zscore(df,'sepal_w')\n",
    "encode_numeric_zscore(df,'petal_l')\n",
    "encode_numeric_zscore(df,'petal_w')\n",
    "species = encode_text_index(df,'species')\n",
    "num_classes = len(species)\n",
    "\n",
    "x,y = to_xy(df,'species')\n",
    "\n",
    "model_dir = 'tmp/iris' \n",
    "\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "classifier = learn.DNNClassifier(\n",
    "    model_dir= model_dir,\n",
    "    hidden_units=[10, 20, 5], n_classes=num_classes, feature_columns=feature_columns)\n",
    "\n",
    "classifier.fit(x, y, steps=1000)\n",
    "\n",
    "pred = list(classifier.predict(x, as_iterable=True))\n",
    "score = metrics.accuracy_score(y, pred)\n",
    "print(\"Accuarcy before save: {}\".format(score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy before save: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as learn\n",
    "import numpy as np\n",
    "from tensorflow.contrib.learn.python.learn.metric_spec import MetricSpec\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "path = \"./data/\"\n",
    "    \n",
    "filename = os.path.join(path,\"iris.csv\")    \n",
    "df = pd.read_csv(filename,na_values=['NA','?'])\n",
    "\n",
    "encode_numeric_zscore(df,'petal_w')\n",
    "encode_numeric_zscore(df,'petal_l')\n",
    "encode_numeric_zscore(df,'sepal_w')\n",
    "encode_numeric_zscore(df,'sepal_l')\n",
    "species = encode_text_index(df,\"species\")\n",
    "num_classes = len(species)\n",
    "\n",
    "x, y = to_xy(df,'species')\n",
    "    \n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=45)\n",
    "\n",
    "model_dir = 'tmp/iris' \n",
    "\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "classifier = learn.DNNClassifier(\n",
    "    model_dir= model_dir,\n",
    "    config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1),\n",
    "    hidden_units=[10, 20, 5], n_classes=num_classes, feature_columns=feature_columns)\n",
    "\n",
    "validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    every_n_steps=500,\n",
    "    early_stopping_metric=\"loss\",\n",
    "    early_stopping_metric_minimize=True,\n",
    "    early_stopping_rounds=50)\n",
    "    \n",
    "classifier.fit(x_train, y_train,monitors=[validation_monitor],steps=10000)\n",
    "    \n",
    "pred = list(classifier.predict(x_test, as_iterable=True))\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"Accuarcy before save: {}\".format(score))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As percent probability\n",
      "[ 99.99   0.01   0.  ]\n",
      "Numpy array of predictions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.9999,  0.0001,  0.    ], dtype=float32),\n",
       " array([ 0.9992,  0.0008,  0.    ], dtype=float32),\n",
       " array([ 0.    ,  0.273 ,  0.7269], dtype=float32),\n",
       " array([ 1.,  0.,  0.], dtype=float32),\n",
       " array([ 0.9999,  0.0001,  0.    ], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss score: 0.1511291688804347\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "pred = list(classifier.predict_proba(x_test, as_iterable=True))\n",
    "\n",
    "print(\"As percent probability\")\n",
    "print(pred[0]*100)\n",
    "\n",
    "print(\"Numpy array of predictions\")\n",
    "display(pred[0:5])\n",
    "\n",
    "score = metrics.log_loss(y_test, pred)\n",
    "print(\"Log loss score: {}\".format(score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x12470b080>, '_master': '', '_num_ps_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', 'tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", 'tf_random_seed': None, 'save_summary_steps': 100, 'save_checkpoints_secs': 1, 'save_checkpoints_steps': None, 'keep_checkpoint_max': 5, 'keep_checkpoint_every_n_hours': 10000}\n",
      "WARNING:tensorflow:From /Users/Simone/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:322 in __init__.: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "WARNING:tensorflow:From /Users/Simone/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/Simone/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/Simone/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:loss = 0.00918128, step = 1502\n",
      "INFO:tensorflow:Saving checkpoints for 1502 into tmp/iris/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:From /Users/Simone/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/Simone/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/Simone/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n",
      "INFO:tensorflow:Restored model from tmp/iris\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 1502.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for step 1502: accuracy = 0.947368, loss = 0.208661\n",
      "INFO:tensorflow:Validation (step 1502): accuracy = 0.947368, loss = 0.208661, global_step = 1502\n",
      "INFO:tensorflow:Saving checkpoints for 1503 into tmp/iris/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 0.00801592, step = 1602\n",
      "INFO:tensorflow:global_step/sec: 47.7059\n",
      "INFO:tensorflow:loss = 0.00695181, step = 1702\n",
      "INFO:tensorflow:global_step/sec: 638.789\n",
      "INFO:tensorflow:loss = 0.00596129, step = 1802\n",
      "INFO:tensorflow:global_step/sec: 640.275\n",
      "INFO:tensorflow:loss = 0.00514576, step = 1902\n",
      "INFO:tensorflow:global_step/sec: 648.122\n",
      "INFO:tensorflow:Saving checkpoints for 1922 into tmp/iris/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 0.00440131, step = 2002\n",
      "INFO:tensorflow:global_step/sec: 166.684\n",
      "WARNING:tensorflow:From /Users/Simone/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/Simone/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/Simone/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n",
      "INFO:tensorflow:Restored model from tmp/iris\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 1922.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for step 1922: accuracy = 0.973684, loss = 0.242986\n",
      "INFO:tensorflow:Validation (step 2002): accuracy = 0.973684, loss = 0.242986, global_step = 1922\n",
      "INFO:tensorflow:Stopping. Best step: 1502 with loss = 0.2086605578660965.\n",
      "INFO:tensorflow:Saving checkpoints for 2002 into tmp/iris/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:Loss for final step: 0.00440131.\n",
      "WARNING:tensorflow:From /Users/Simone/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:348 in predict.: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/Simone/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:348 in predict.: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From /Users/Simone/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:348 in predict.: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with as_iterable is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n",
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n",
      "INFO:tensorflow:Loading model from checkpoint: tmp/iris/model.ckpt-2002-?????-of-00001.\n",
      "Confusion matrix\n",
      "[[14  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  1 14]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAAEmCAYAAADfpHMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123dade48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as learn\n",
    "import numpy as np\n",
    "from tensorflow.contrib.learn.python.learn.metric_spec import MetricSpec\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "path = \"./data/\"\n",
    "    \n",
    "filename = os.path.join(path,\"iris.csv\")    \n",
    "df = pd.read_csv(filename,na_values=['NA','?'])\n",
    "\n",
    "encode_numeric_zscore(df,'petal_w')\n",
    "encode_numeric_zscore(df,'petal_l')\n",
    "encode_numeric_zscore(df,'sepal_w')\n",
    "encode_numeric_zscore(df,'sepal_l')\n",
    "species = encode_text_index(df,\"species\")\n",
    "num_classes = len(species)\n",
    "\n",
    "x, y = to_xy(df,'species')\n",
    "    \n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=45)\n",
    "\n",
    "model_dir = 'tmp/iris' \n",
    "\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "classifier = learn.DNNClassifier(\n",
    "    model_dir= model_dir,\n",
    "    config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1),\n",
    "    hidden_units=[10, 20, 5], n_classes=num_classes, feature_columns=feature_columns)\n",
    "\n",
    "validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    every_n_steps=500,\n",
    "    early_stopping_metric=\"loss\",\n",
    "    early_stopping_metric_minimize=True,\n",
    "    early_stopping_rounds=50)\n",
    "    \n",
    "classifier.fit(x_train, y_train,monitors=[validation_monitor],steps=10000)\n",
    "    \n",
    "pred = list(classifier.predict(x_test, as_iterable=True))\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix')\n",
    "print(cm)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, species)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Fold score (Accuracy): 1.0\n",
      "Fold #2\n",
      "Fold score (Accuracy): 1.0\n",
      "Fold #3\n",
      "Fold score (Accuracy): 0.983192080250175\n",
      "Fold #4\n",
      "Fold score (Accuracy): 1.0\n",
      "Fold #5\n",
      "Fold score (Accuracy): 0.983192080250175\n",
      "\n",
      "Cross-validated score (Accuracy): 0.993310961716756\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.contrib.learn as learn\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "path = \"./data/\"\n",
    "filename_read = os.path.join(path,\"iris.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "encode_numeric_zscore(df,'sepal_l')\n",
    "encode_numeric_zscore(df,'sepal_w')\n",
    "encode_numeric_zscore(df,'petal_l')\n",
    "encode_numeric_zscore(df,'petal_w')\n",
    "species = encode_text_index(df,'species')\n",
    "num_classes = len(species)\n",
    "\n",
    "x,y = to_xy(df,'species')\n",
    "\n",
    "kf = KFold(5)\n",
    "    \n",
    "all_y_test = []\n",
    "all_y_pred = []\n",
    "fold = 0\n",
    "for train, test in kf.split(x):        \n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    model_dir = 'tmp/irisKF' + str(fold)\n",
    "\n",
    "    feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "    classifier = learn.DNNClassifier(\n",
    "    model_dir= model_dir,\n",
    "    hidden_units=[10, 20, 5], n_classes=num_classes, feature_columns=feature_columns)\n",
    "\n",
    "    validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "        x_test,\n",
    "        y_test,\n",
    "        every_n_steps=50,\n",
    "        early_stopping_metric=\"loss\",\n",
    "        early_stopping_metric_minimize=True,\n",
    "        early_stopping_rounds=50)\n",
    "    \n",
    "    classifier.fit(x, y, steps=1000)\n",
    "\n",
    "    pred = list(classifier.predict(x_test, as_iterable=True))\n",
    "    \n",
    "    all_y_test.append(y_test)\n",
    "    all_y_pred.append(pred)        \n",
    "\n",
    "    score = np.sqrt(metrics.accuracy_score(pred,y_test))\n",
    "    print(\"Fold score (Accuracy): {}\".format(score))\n",
    "\n",
    "\n",
    "all_y_test = np.concatenate(all_y_test)\n",
    "all_y_pred = np.concatenate(all_y_pred)\n",
    "score = np.sqrt(metrics.accuracy_score(all_y_pred,all_y_test))\n",
    "print()\n",
    "print(\"Cross-validated score (Accuracy): {}\".format(score))    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
