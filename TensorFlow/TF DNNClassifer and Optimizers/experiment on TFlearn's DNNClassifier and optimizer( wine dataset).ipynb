{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_text_index(df,name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "def encode_numeric_zscore(df,name,mean=None,sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name]-mean)/sd\n",
    "    \n",
    "def to_xy(df,target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    \n",
    "    if target_type in (np.int64, np.int32):\n",
    "        return df.as_matrix(result).astype(np.float32),df.as_matrix([target]).astype(np.int32)\n",
    "    else:\n",
    "        return df.as_matrix(result).astype(np.float32),df.as_matrix([target]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score: 1.0\n",
      "Excution time=  3.8375167846679688 secs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od28_od315</th>\n",
       "      <th>proline</th>\n",
       "      <th>expected</th>\n",
       "      <th>predicted</th>\n",
       "      <th>expected_str</th>\n",
       "      <th>predicted_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.514341</td>\n",
       "      <td>-0.560668</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>-1.166303</td>\n",
       "      <td>1.908522</td>\n",
       "      <td>0.806722</td>\n",
       "      <td>1.031908</td>\n",
       "      <td>-0.657708</td>\n",
       "      <td>1.221438</td>\n",
       "      <td>0.251009</td>\n",
       "      <td>0.361158</td>\n",
       "      <td>1.842721</td>\n",
       "      <td>1.010159</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.245597</td>\n",
       "      <td>-0.498009</td>\n",
       "      <td>-0.825667</td>\n",
       "      <td>-2.483841</td>\n",
       "      <td>0.018094</td>\n",
       "      <td>0.567048</td>\n",
       "      <td>0.731565</td>\n",
       "      <td>-0.818411</td>\n",
       "      <td>-0.543189</td>\n",
       "      <td>-0.292496</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>1.110317</td>\n",
       "      <td>0.962526</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.196325</td>\n",
       "      <td>0.021172</td>\n",
       "      <td>1.106214</td>\n",
       "      <td>-0.267982</td>\n",
       "      <td>0.088110</td>\n",
       "      <td>0.806722</td>\n",
       "      <td>1.212114</td>\n",
       "      <td>-0.497005</td>\n",
       "      <td>2.129959</td>\n",
       "      <td>0.268263</td>\n",
       "      <td>0.317409</td>\n",
       "      <td>0.786369</td>\n",
       "      <td>1.391224</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.686791</td>\n",
       "      <td>-0.345835</td>\n",
       "      <td>0.486554</td>\n",
       "      <td>-0.806975</td>\n",
       "      <td>0.928300</td>\n",
       "      <td>2.484437</td>\n",
       "      <td>1.462399</td>\n",
       "      <td>-0.979113</td>\n",
       "      <td>1.029251</td>\n",
       "      <td>1.182732</td>\n",
       "      <td>-0.426341</td>\n",
       "      <td>1.180741</td>\n",
       "      <td>2.328007</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.294868</td>\n",
       "      <td>0.227053</td>\n",
       "      <td>1.835226</td>\n",
       "      <td>0.450674</td>\n",
       "      <td>1.278379</td>\n",
       "      <td>0.806722</td>\n",
       "      <td>0.661485</td>\n",
       "      <td>0.226158</td>\n",
       "      <td>0.400275</td>\n",
       "      <td>-0.318377</td>\n",
       "      <td>0.361158</td>\n",
       "      <td>0.448336</td>\n",
       "      <td>-0.037767</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1.477387</td>\n",
       "      <td>-0.515911</td>\n",
       "      <td>0.304301</td>\n",
       "      <td>-1.286079</td>\n",
       "      <td>0.858284</td>\n",
       "      <td>1.557699</td>\n",
       "      <td>1.362285</td>\n",
       "      <td>-0.175599</td>\n",
       "      <td>0.662349</td>\n",
       "      <td>0.729811</td>\n",
       "      <td>0.404908</td>\n",
       "      <td>0.335659</td>\n",
       "      <td>2.232741</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1.711427</td>\n",
       "      <td>-0.417446</td>\n",
       "      <td>0.304301</td>\n",
       "      <td>-1.465743</td>\n",
       "      <td>-0.261969</td>\n",
       "      <td>0.327374</td>\n",
       "      <td>0.491291</td>\n",
       "      <td>-0.497005</td>\n",
       "      <td>0.679820</td>\n",
       "      <td>0.082781</td>\n",
       "      <td>0.273659</td>\n",
       "      <td>1.363842</td>\n",
       "      <td>1.724655</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1.304936</td>\n",
       "      <td>-0.166807</td>\n",
       "      <td>0.887510</td>\n",
       "      <td>-0.567423</td>\n",
       "      <td>1.488427</td>\n",
       "      <td>0.487157</td>\n",
       "      <td>0.481280</td>\n",
       "      <td>-0.416654</td>\n",
       "      <td>-0.595603</td>\n",
       "      <td>-0.003490</td>\n",
       "      <td>0.448658</td>\n",
       "      <td>1.363842</td>\n",
       "      <td>1.740533</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2.253415</td>\n",
       "      <td>-0.623328</td>\n",
       "      <td>-0.716315</td>\n",
       "      <td>-1.645408</td>\n",
       "      <td>-0.191954</td>\n",
       "      <td>0.806722</td>\n",
       "      <td>0.951817</td>\n",
       "      <td>-0.577356</td>\n",
       "      <td>0.679820</td>\n",
       "      <td>0.061213</td>\n",
       "      <td>0.536158</td>\n",
       "      <td>0.335659</td>\n",
       "      <td>0.946649</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1.058578</td>\n",
       "      <td>-0.882918</td>\n",
       "      <td>-0.351810</td>\n",
       "      <td>-1.046527</td>\n",
       "      <td>-0.121938</td>\n",
       "      <td>1.094330</td>\n",
       "      <td>1.122011</td>\n",
       "      <td>-1.139816</td>\n",
       "      <td>0.452690</td>\n",
       "      <td>0.932547</td>\n",
       "      <td>0.229909</td>\n",
       "      <td>1.321588</td>\n",
       "      <td>0.946649</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1.354208</td>\n",
       "      <td>-0.157856</td>\n",
       "      <td>-0.242458</td>\n",
       "      <td>-0.447646</td>\n",
       "      <td>0.368173</td>\n",
       "      <td>1.046395</td>\n",
       "      <td>1.292205</td>\n",
       "      <td>-1.139816</td>\n",
       "      <td>1.378682</td>\n",
       "      <td>0.298458</td>\n",
       "      <td>1.279908</td>\n",
       "      <td>0.786369</td>\n",
       "      <td>2.423273</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1.378844</td>\n",
       "      <td>-0.766550</td>\n",
       "      <td>-0.169557</td>\n",
       "      <td>-0.806975</td>\n",
       "      <td>-0.331985</td>\n",
       "      <td>-0.151973</td>\n",
       "      <td>0.401188</td>\n",
       "      <td>-0.818411</td>\n",
       "      <td>-0.036514</td>\n",
       "      <td>-0.025057</td>\n",
       "      <td>0.929908</td>\n",
       "      <td>0.293405</td>\n",
       "      <td>1.692900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.923081</td>\n",
       "      <td>-0.542765</td>\n",
       "      <td>0.158499</td>\n",
       "      <td>-1.046527</td>\n",
       "      <td>-0.752080</td>\n",
       "      <td>0.487157</td>\n",
       "      <td>0.731565</td>\n",
       "      <td>-0.577356</td>\n",
       "      <td>0.382804</td>\n",
       "      <td>0.233755</td>\n",
       "      <td>0.842408</td>\n",
       "      <td>0.406082</td>\n",
       "      <td>1.819921</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>2.154872</td>\n",
       "      <td>-0.542765</td>\n",
       "      <td>0.085597</td>\n",
       "      <td>-2.423952</td>\n",
       "      <td>-0.612049</td>\n",
       "      <td>1.286069</td>\n",
       "      <td>1.662628</td>\n",
       "      <td>0.547563</td>\n",
       "      <td>2.129959</td>\n",
       "      <td>0.147484</td>\n",
       "      <td>1.279908</td>\n",
       "      <td>0.166643</td>\n",
       "      <td>1.280080</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1.699109</td>\n",
       "      <td>-0.417446</td>\n",
       "      <td>0.049147</td>\n",
       "      <td>-2.244288</td>\n",
       "      <td>0.158126</td>\n",
       "      <td>1.605634</td>\n",
       "      <td>1.612571</td>\n",
       "      <td>-0.577356</td>\n",
       "      <td>2.392033</td>\n",
       "      <td>1.053326</td>\n",
       "      <td>1.061158</td>\n",
       "      <td>0.546929</td>\n",
       "      <td>2.540768</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.775267</td>\n",
       "      <td>-0.471154</td>\n",
       "      <td>1.215566</td>\n",
       "      <td>-0.687199</td>\n",
       "      <td>0.858284</td>\n",
       "      <td>0.886613</td>\n",
       "      <td>0.881737</td>\n",
       "      <td>-0.497005</td>\n",
       "      <td>-0.228701</td>\n",
       "      <td>0.967055</td>\n",
       "      <td>1.411158</td>\n",
       "      <td>0.377913</td>\n",
       "      <td>1.788166</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1.600566</td>\n",
       "      <td>-0.372689</td>\n",
       "      <td>1.288467</td>\n",
       "      <td>0.151234</td>\n",
       "      <td>1.418411</td>\n",
       "      <td>0.806722</td>\n",
       "      <td>1.111999</td>\n",
       "      <td>-0.255951</td>\n",
       "      <td>0.662349</td>\n",
       "      <td>0.492567</td>\n",
       "      <td>0.492408</td>\n",
       "      <td>0.053965</td>\n",
       "      <td>1.692900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1.021625</td>\n",
       "      <td>-0.685988</td>\n",
       "      <td>0.923961</td>\n",
       "      <td>0.151234</td>\n",
       "      <td>1.068331</td>\n",
       "      <td>1.046395</td>\n",
       "      <td>1.372297</td>\n",
       "      <td>0.306509</td>\n",
       "      <td>0.225560</td>\n",
       "      <td>0.665108</td>\n",
       "      <td>0.754908</td>\n",
       "      <td>-0.058713</td>\n",
       "      <td>1.216569</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1.465069</td>\n",
       "      <td>-0.668085</td>\n",
       "      <td>0.413653</td>\n",
       "      <td>-0.896807</td>\n",
       "      <td>0.578221</td>\n",
       "      <td>1.605634</td>\n",
       "      <td>1.902902</td>\n",
       "      <td>-0.336302</td>\n",
       "      <td>0.470162</td>\n",
       "      <td>1.570950</td>\n",
       "      <td>1.192408</td>\n",
       "      <td>0.293405</td>\n",
       "      <td>2.963114</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.787585</td>\n",
       "      <td>0.683574</td>\n",
       "      <td>0.705257</td>\n",
       "      <td>-1.286079</td>\n",
       "      <td>1.138347</td>\n",
       "      <td>0.646939</td>\n",
       "      <td>1.001874</td>\n",
       "      <td>-1.541573</td>\n",
       "      <td>0.120730</td>\n",
       "      <td>0.018078</td>\n",
       "      <td>0.011159</td>\n",
       "      <td>1.053978</td>\n",
       "      <td>0.311541</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1.304936</td>\n",
       "      <td>-0.632279</td>\n",
       "      <td>-0.315359</td>\n",
       "      <td>-1.046527</td>\n",
       "      <td>1.838506</td>\n",
       "      <td>1.126287</td>\n",
       "      <td>1.142034</td>\n",
       "      <td>-0.979113</td>\n",
       "      <td>0.889479</td>\n",
       "      <td>0.255322</td>\n",
       "      <td>0.579908</td>\n",
       "      <td>1.546943</td>\n",
       "      <td>0.105132</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.086987</td>\n",
       "      <td>1.310170</td>\n",
       "      <td>1.033313</td>\n",
       "      <td>-0.267982</td>\n",
       "      <td>0.158126</td>\n",
       "      <td>0.183570</td>\n",
       "      <td>0.381165</td>\n",
       "      <td>-0.898762</td>\n",
       "      <td>0.679820</td>\n",
       "      <td>-0.240734</td>\n",
       "      <td>0.317409</td>\n",
       "      <td>1.279334</td>\n",
       "      <td>0.073376</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0.873810</td>\n",
       "      <td>-0.426398</td>\n",
       "      <td>-0.023754</td>\n",
       "      <td>-0.866863</td>\n",
       "      <td>0.088110</td>\n",
       "      <td>0.503135</td>\n",
       "      <td>0.851702</td>\n",
       "      <td>-0.738059</td>\n",
       "      <td>0.173145</td>\n",
       "      <td>-0.542681</td>\n",
       "      <td>0.667408</td>\n",
       "      <td>1.955399</td>\n",
       "      <td>0.914893</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.185530</td>\n",
       "      <td>-0.659133</td>\n",
       "      <td>0.559455</td>\n",
       "      <td>-0.507534</td>\n",
       "      <td>-0.331985</td>\n",
       "      <td>0.295418</td>\n",
       "      <td>0.341120</td>\n",
       "      <td>-0.818411</td>\n",
       "      <td>-0.228701</td>\n",
       "      <td>-0.486605</td>\n",
       "      <td>0.579908</td>\n",
       "      <td>1.434265</td>\n",
       "      <td>0.851383</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.615134</td>\n",
       "      <td>-0.471154</td>\n",
       "      <td>0.887510</td>\n",
       "      <td>0.151234</td>\n",
       "      <td>-0.261969</td>\n",
       "      <td>0.375309</td>\n",
       "      <td>0.581394</td>\n",
       "      <td>-0.657708</td>\n",
       "      <td>0.120730</td>\n",
       "      <td>-0.663460</td>\n",
       "      <td>0.711158</td>\n",
       "      <td>1.701875</td>\n",
       "      <td>0.311541</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.060828</td>\n",
       "      <td>-0.256321</td>\n",
       "      <td>3.110996</td>\n",
       "      <td>1.648436</td>\n",
       "      <td>1.698474</td>\n",
       "      <td>0.535092</td>\n",
       "      <td>0.651474</td>\n",
       "      <td>0.868969</td>\n",
       "      <td>0.574991</td>\n",
       "      <td>-0.637579</td>\n",
       "      <td>0.754908</td>\n",
       "      <td>0.828623</td>\n",
       "      <td>0.263908</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0.479637</td>\n",
       "      <td>-0.506960</td>\n",
       "      <td>0.923961</td>\n",
       "      <td>-1.016583</td>\n",
       "      <td>-0.472017</td>\n",
       "      <td>0.886613</td>\n",
       "      <td>0.911771</td>\n",
       "      <td>-0.175599</td>\n",
       "      <td>-0.246172</td>\n",
       "      <td>-0.111328</td>\n",
       "      <td>-0.163841</td>\n",
       "      <td>0.856793</td>\n",
       "      <td>1.422979</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0.368776</td>\n",
       "      <td>-0.551717</td>\n",
       "      <td>-0.825667</td>\n",
       "      <td>-0.747087</td>\n",
       "      <td>-0.402001</td>\n",
       "      <td>0.167592</td>\n",
       "      <td>0.160914</td>\n",
       "      <td>-0.738059</td>\n",
       "      <td>-0.420888</td>\n",
       "      <td>-0.477978</td>\n",
       "      <td>0.273659</td>\n",
       "      <td>0.222981</td>\n",
       "      <td>1.708777</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1.070896</td>\n",
       "      <td>-0.390592</td>\n",
       "      <td>1.580071</td>\n",
       "      <td>-0.028430</td>\n",
       "      <td>0.508205</td>\n",
       "      <td>1.046395</td>\n",
       "      <td>0.941805</td>\n",
       "      <td>0.065455</td>\n",
       "      <td>0.295446</td>\n",
       "      <td>-0.240734</td>\n",
       "      <td>1.279908</td>\n",
       "      <td>1.110317</td>\n",
       "      <td>0.533829</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>1.255665</td>\n",
       "      <td>-0.587522</td>\n",
       "      <td>-0.570513</td>\n",
       "      <td>-1.046527</td>\n",
       "      <td>-0.261969</td>\n",
       "      <td>0.567048</td>\n",
       "      <td>0.301074</td>\n",
       "      <td>-0.818411</td>\n",
       "      <td>0.679820</td>\n",
       "      <td>-0.154463</td>\n",
       "      <td>0.361158</td>\n",
       "      <td>1.377926</td>\n",
       "      <td>0.914893</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2</td>\n",
       "      <td>0.393412</td>\n",
       "      <td>0.808893</td>\n",
       "      <td>0.049147</td>\n",
       "      <td>0.600395</td>\n",
       "      <td>-0.542033</td>\n",
       "      <td>-0.583385</td>\n",
       "      <td>-1.270720</td>\n",
       "      <td>0.708266</td>\n",
       "      <td>-0.595603</td>\n",
       "      <td>1.450171</td>\n",
       "      <td>-1.782590</td>\n",
       "      <td>-1.396759</td>\n",
       "      <td>-0.307688</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2</td>\n",
       "      <td>0.097782</td>\n",
       "      <td>1.399684</td>\n",
       "      <td>-0.023754</td>\n",
       "      <td>0.600395</td>\n",
       "      <td>0.928300</td>\n",
       "      <td>-1.414254</td>\n",
       "      <td>-0.640000</td>\n",
       "      <td>-0.175599</td>\n",
       "      <td>-0.787791</td>\n",
       "      <td>1.872897</td>\n",
       "      <td>-1.695090</td>\n",
       "      <td>-1.805215</td>\n",
       "      <td>-0.625242</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2</td>\n",
       "      <td>0.615134</td>\n",
       "      <td>0.701476</td>\n",
       "      <td>0.923961</td>\n",
       "      <td>1.348995</td>\n",
       "      <td>1.628458</td>\n",
       "      <td>-1.430232</td>\n",
       "      <td>-0.459794</td>\n",
       "      <td>-1.139816</td>\n",
       "      <td>-0.595603</td>\n",
       "      <td>1.527814</td>\n",
       "      <td>-1.607590</td>\n",
       "      <td>-1.847469</td>\n",
       "      <td>-0.784018</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.259437</td>\n",
       "      <td>0.298664</td>\n",
       "      <td>0.413653</td>\n",
       "      <td>0.750115</td>\n",
       "      <td>0.858284</td>\n",
       "      <td>-1.302406</td>\n",
       "      <td>-0.670034</td>\n",
       "      <td>-0.979113</td>\n",
       "      <td>-0.578132</td>\n",
       "      <td>2.476791</td>\n",
       "      <td>-2.088840</td>\n",
       "      <td>-1.608029</td>\n",
       "      <td>-0.847529</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2</td>\n",
       "      <td>0.134736</td>\n",
       "      <td>-0.390592</td>\n",
       "      <td>1.397819</td>\n",
       "      <td>1.798156</td>\n",
       "      <td>1.138347</td>\n",
       "      <td>-0.151973</td>\n",
       "      <td>-0.750126</td>\n",
       "      <td>-0.818411</td>\n",
       "      <td>-0.053985</td>\n",
       "      <td>0.880784</td>\n",
       "      <td>-1.520090</td>\n",
       "      <td>-1.805215</td>\n",
       "      <td>-1.022184</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2</td>\n",
       "      <td>0.282551</td>\n",
       "      <td>0.862601</td>\n",
       "      <td>-0.315359</td>\n",
       "      <td>-0.297926</td>\n",
       "      <td>-0.121938</td>\n",
       "      <td>-0.791103</td>\n",
       "      <td>-1.200640</td>\n",
       "      <td>1.993888</td>\n",
       "      <td>0.487633</td>\n",
       "      <td>2.356012</td>\n",
       "      <td>-1.738840</td>\n",
       "      <td>-1.551690</td>\n",
       "      <td>-0.228300</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.518113</td>\n",
       "      <td>-0.936626</td>\n",
       "      <td>-0.971470</td>\n",
       "      <td>0.151234</td>\n",
       "      <td>0.228141</td>\n",
       "      <td>-1.302406</td>\n",
       "      <td>-1.450926</td>\n",
       "      <td>1.351077</td>\n",
       "      <td>-0.333530</td>\n",
       "      <td>1.096461</td>\n",
       "      <td>-1.651340</td>\n",
       "      <td>-1.495352</td>\n",
       "      <td>-0.339443</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2</td>\n",
       "      <td>0.208643</td>\n",
       "      <td>2.554412</td>\n",
       "      <td>-0.169557</td>\n",
       "      <td>0.750115</td>\n",
       "      <td>-0.472017</td>\n",
       "      <td>-0.886972</td>\n",
       "      <td>-1.400868</td>\n",
       "      <td>1.993888</td>\n",
       "      <td>-0.071457</td>\n",
       "      <td>1.225867</td>\n",
       "      <td>-1.563840</td>\n",
       "      <td>-1.593945</td>\n",
       "      <td>-0.069523</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2</td>\n",
       "      <td>1.033943</td>\n",
       "      <td>1.596615</td>\n",
       "      <td>0.049147</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>-0.752080</td>\n",
       "      <td>-0.791103</td>\n",
       "      <td>-1.200640</td>\n",
       "      <td>0.949320</td>\n",
       "      <td>-0.053985</td>\n",
       "      <td>1.704669</td>\n",
       "      <td>-1.695090</td>\n",
       "      <td>-1.368589</td>\n",
       "      <td>-0.847529</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.678246</td>\n",
       "      <td>0.620914</td>\n",
       "      <td>0.996862</td>\n",
       "      <td>2.247316</td>\n",
       "      <td>-0.191954</td>\n",
       "      <td>-0.631320</td>\n",
       "      <td>-1.450926</td>\n",
       "      <td>2.154591</td>\n",
       "      <td>-0.787791</td>\n",
       "      <td>1.053326</td>\n",
       "      <td>-1.257591</td>\n",
       "      <td>-1.241827</td>\n",
       "      <td>0.422685</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2</td>\n",
       "      <td>1.649838</td>\n",
       "      <td>-0.587522</td>\n",
       "      <td>1.215566</td>\n",
       "      <td>1.648436</td>\n",
       "      <td>-0.121938</td>\n",
       "      <td>0.806722</td>\n",
       "      <td>-0.720092</td>\n",
       "      <td>1.351077</td>\n",
       "      <td>1.937772</td>\n",
       "      <td>3.425768</td>\n",
       "      <td>-1.695090</td>\n",
       "      <td>-0.917879</td>\n",
       "      <td>-0.275933</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2</td>\n",
       "      <td>0.590498</td>\n",
       "      <td>-0.596474</td>\n",
       "      <td>0.996862</td>\n",
       "      <td>0.899835</td>\n",
       "      <td>-0.752080</td>\n",
       "      <td>0.487157</td>\n",
       "      <td>-0.930331</td>\n",
       "      <td>1.270726</td>\n",
       "      <td>1.221438</td>\n",
       "      <td>2.886577</td>\n",
       "      <td>-1.695090</td>\n",
       "      <td>-1.171404</td>\n",
       "      <td>-0.402954</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.789107</td>\n",
       "      <td>1.337024</td>\n",
       "      <td>0.049147</td>\n",
       "      <td>0.450674</td>\n",
       "      <td>-0.822096</td>\n",
       "      <td>0.007810</td>\n",
       "      <td>-1.110537</td>\n",
       "      <td>1.110023</td>\n",
       "      <td>-0.962506</td>\n",
       "      <td>1.118029</td>\n",
       "      <td>-1.738840</td>\n",
       "      <td>-1.453098</td>\n",
       "      <td>-0.720508</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2</td>\n",
       "      <td>0.849174</td>\n",
       "      <td>0.826796</td>\n",
       "      <td>0.632356</td>\n",
       "      <td>0.151234</td>\n",
       "      <td>0.508205</td>\n",
       "      <td>-0.743168</td>\n",
       "      <td>-1.470948</td>\n",
       "      <td>1.110023</td>\n",
       "      <td>-1.381823</td>\n",
       "      <td>0.354534</td>\n",
       "      <td>0.011159</td>\n",
       "      <td>-1.115065</td>\n",
       "      <td>-0.212422</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.185530</td>\n",
       "      <td>0.835747</td>\n",
       "      <td>0.778159</td>\n",
       "      <td>0.750115</td>\n",
       "      <td>0.438189</td>\n",
       "      <td>-1.030776</td>\n",
       "      <td>-1.430903</td>\n",
       "      <td>1.913537</td>\n",
       "      <td>-1.102279</td>\n",
       "      <td>0.225128</td>\n",
       "      <td>-0.382591</td>\n",
       "      <td>-0.706609</td>\n",
       "      <td>-0.561731</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.050033</td>\n",
       "      <td>0.996872</td>\n",
       "      <td>-0.060205</td>\n",
       "      <td>-0.297926</td>\n",
       "      <td>0.438189</td>\n",
       "      <td>-1.446211</td>\n",
       "      <td>-1.330789</td>\n",
       "      <td>0.306509</td>\n",
       "      <td>-1.137222</td>\n",
       "      <td>0.095722</td>\n",
       "      <td>-1.213841</td>\n",
       "      <td>-1.213658</td>\n",
       "      <td>-0.228300</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2</td>\n",
       "      <td>0.960035</td>\n",
       "      <td>0.379227</td>\n",
       "      <td>-0.242458</td>\n",
       "      <td>0.750115</td>\n",
       "      <td>-0.682064</td>\n",
       "      <td>-1.510123</td>\n",
       "      <td>-1.350811</td>\n",
       "      <td>0.386860</td>\n",
       "      <td>-0.979978</td>\n",
       "      <td>1.950540</td>\n",
       "      <td>-1.126341</td>\n",
       "      <td>-1.312251</td>\n",
       "      <td>-0.418832</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2</td>\n",
       "      <td>0.898446</td>\n",
       "      <td>1.811448</td>\n",
       "      <td>-0.388260</td>\n",
       "      <td>0.899835</td>\n",
       "      <td>-0.822096</td>\n",
       "      <td>-1.621971</td>\n",
       "      <td>-1.561051</td>\n",
       "      <td>1.270726</td>\n",
       "      <td>-0.770319</td>\n",
       "      <td>0.673735</td>\n",
       "      <td>-0.776341</td>\n",
       "      <td>-1.213658</td>\n",
       "      <td>-0.720508</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2</td>\n",
       "      <td>0.553544</td>\n",
       "      <td>1.220657</td>\n",
       "      <td>0.851060</td>\n",
       "      <td>1.049555</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>-0.950885</td>\n",
       "      <td>-1.110537</td>\n",
       "      <td>0.547563</td>\n",
       "      <td>-0.228701</td>\n",
       "      <td>2.425029</td>\n",
       "      <td>-0.470091</td>\n",
       "      <td>-1.481267</td>\n",
       "      <td>-0.164789</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.222483</td>\n",
       "      <td>0.925261</td>\n",
       "      <td>-0.242458</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>-0.822096</td>\n",
       "      <td>-1.302406</td>\n",
       "      <td>-1.370834</td>\n",
       "      <td>0.306509</td>\n",
       "      <td>-1.084807</td>\n",
       "      <td>2.243861</td>\n",
       "      <td>-1.038841</td>\n",
       "      <td>-1.213658</td>\n",
       "      <td>-0.196544</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2</td>\n",
       "      <td>0.713677</td>\n",
       "      <td>0.218102</td>\n",
       "      <td>1.179115</td>\n",
       "      <td>1.498716</td>\n",
       "      <td>0.368173</td>\n",
       "      <td>-1.190559</td>\n",
       "      <td>-1.190629</td>\n",
       "      <td>0.226158</td>\n",
       "      <td>-0.088928</td>\n",
       "      <td>1.553695</td>\n",
       "      <td>-0.951341</td>\n",
       "      <td>-1.143234</td>\n",
       "      <td>0.009866</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2</td>\n",
       "      <td>0.491955</td>\n",
       "      <td>2.026281</td>\n",
       "      <td>1.798775</td>\n",
       "      <td>1.648436</td>\n",
       "      <td>0.858284</td>\n",
       "      <td>-0.503494</td>\n",
       "      <td>-1.070491</td>\n",
       "      <td>-0.738059</td>\n",
       "      <td>-0.840205</td>\n",
       "      <td>1.484679</td>\n",
       "      <td>-1.257591</td>\n",
       "      <td>-0.974218</td>\n",
       "      <td>-0.371199</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.986193</td>\n",
       "      <td>0.620914</td>\n",
       "      <td>-0.169557</td>\n",
       "      <td>-0.148206</td>\n",
       "      <td>-0.261969</td>\n",
       "      <td>-1.669906</td>\n",
       "      <td>-1.541028</td>\n",
       "      <td>0.306509</td>\n",
       "      <td>-1.504124</td>\n",
       "      <td>0.190619</td>\n",
       "      <td>-1.301341</td>\n",
       "      <td>-1.100980</td>\n",
       "      <td>-0.752263</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.284073</td>\n",
       "      <td>0.048026</td>\n",
       "      <td>-0.315359</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>-0.962128</td>\n",
       "      <td>-1.446211</td>\n",
       "      <td>-1.521006</td>\n",
       "      <td>0.949320</td>\n",
       "      <td>-1.661368</td>\n",
       "      <td>2.088573</td>\n",
       "      <td>-1.695090</td>\n",
       "      <td>-1.382674</td>\n",
       "      <td>-0.879284</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2</td>\n",
       "      <td>1.428115</td>\n",
       "      <td>0.155442</td>\n",
       "      <td>0.413653</td>\n",
       "      <td>0.151234</td>\n",
       "      <td>-0.612049</td>\n",
       "      <td>-0.982841</td>\n",
       "      <td>-1.330789</td>\n",
       "      <td>0.627915</td>\n",
       "      <td>-0.613075</td>\n",
       "      <td>2.002303</td>\n",
       "      <td>-1.476340</td>\n",
       "      <td>-1.269997</td>\n",
       "      <td>-0.275933</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2</td>\n",
       "      <td>0.873810</td>\n",
       "      <td>2.966176</td>\n",
       "      <td>0.304301</td>\n",
       "      <td>0.300954</td>\n",
       "      <td>-0.331985</td>\n",
       "      <td>-0.982841</td>\n",
       "      <td>-1.420891</td>\n",
       "      <td>1.270726</td>\n",
       "      <td>-0.927563</td>\n",
       "      <td>1.139596</td>\n",
       "      <td>-1.388840</td>\n",
       "      <td>-1.227742</td>\n",
       "      <td>-0.021890</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2</td>\n",
       "      <td>0.491955</td>\n",
       "      <td>1.408636</td>\n",
       "      <td>0.413653</td>\n",
       "      <td>1.049555</td>\n",
       "      <td>0.158126</td>\n",
       "      <td>-0.791103</td>\n",
       "      <td>-1.280731</td>\n",
       "      <td>0.547563</td>\n",
       "      <td>-0.316058</td>\n",
       "      <td>0.967055</td>\n",
       "      <td>-1.126341</td>\n",
       "      <td>-1.481267</td>\n",
       "      <td>0.009866</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2</td>\n",
       "      <td>0.331822</td>\n",
       "      <td>1.739837</td>\n",
       "      <td>-0.388260</td>\n",
       "      <td>0.151234</td>\n",
       "      <td>1.418411</td>\n",
       "      <td>-1.126646</td>\n",
       "      <td>-1.340800</td>\n",
       "      <td>0.547563</td>\n",
       "      <td>-0.420888</td>\n",
       "      <td>2.217979</td>\n",
       "      <td>-1.607590</td>\n",
       "      <td>-1.481267</td>\n",
       "      <td>0.279786</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2</td>\n",
       "      <td>0.208643</td>\n",
       "      <td>0.227053</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>0.151234</td>\n",
       "      <td>1.418411</td>\n",
       "      <td>-1.030776</td>\n",
       "      <td>-1.350811</td>\n",
       "      <td>1.351077</td>\n",
       "      <td>-0.228701</td>\n",
       "      <td>1.829761</td>\n",
       "      <td>-1.563840</td>\n",
       "      <td>-1.396759</td>\n",
       "      <td>0.295664</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2</td>\n",
       "      <td>1.391162</td>\n",
       "      <td>1.578712</td>\n",
       "      <td>1.361368</td>\n",
       "      <td>1.498716</td>\n",
       "      <td>-0.261969</td>\n",
       "      <td>-0.391646</td>\n",
       "      <td>-1.270720</td>\n",
       "      <td>1.592131</td>\n",
       "      <td>-0.420888</td>\n",
       "      <td>1.786626</td>\n",
       "      <td>-1.520090</td>\n",
       "      <td>-1.424928</td>\n",
       "      <td>-0.593486</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid       ash  alcalinity_ash  magnesium  total_phenols  \\\n",
       "0          0    1.514341 -0.560668        0.231400  -1.166303       1.908522   \n",
       "1          0    0.245597 -0.498009       -0.825667  -2.483841       0.018094   \n",
       "2          0    0.196325  0.021172        1.106214  -0.267982       0.088110   \n",
       "3          0    1.686791 -0.345835        0.486554  -0.806975       0.928300   \n",
       "4          0    0.294868  0.227053        1.835226   0.450674       1.278379   \n",
       "5          0    1.477387 -0.515911        0.304301  -1.286079       0.858284   \n",
       "6          0    1.711427 -0.417446        0.304301  -1.465743      -0.261969   \n",
       "7          0    1.304936 -0.166807        0.887510  -0.567423       1.488427   \n",
       "8          0    2.253415 -0.623328       -0.716315  -1.645408      -0.191954   \n",
       "9          0    1.058578 -0.882918       -0.351810  -1.046527      -0.121938   \n",
       "10         0    1.354208 -0.157856       -0.242458  -0.447646       0.368173   \n",
       "11         0    1.378844 -0.766550       -0.169557  -0.806975      -0.331985   \n",
       "12         0    0.923081 -0.542765        0.158499  -1.046527      -0.752080   \n",
       "13         0    2.154872 -0.542765        0.085597  -2.423952      -0.612049   \n",
       "14         0    1.699109 -0.417446        0.049147  -2.244288       0.158126   \n",
       "15         0    0.775267 -0.471154        1.215566  -0.687199       0.858284   \n",
       "16         0    1.600566 -0.372689        1.288467   0.151234       1.418411   \n",
       "17         0    1.021625 -0.685988        0.923961   0.151234       1.068331   \n",
       "18         0    1.465069 -0.668085        0.413653  -0.896807       0.578221   \n",
       "19         0    0.787585  0.683574        0.705257  -1.286079       1.138347   \n",
       "20         0    1.304936 -0.632279       -0.315359  -1.046527       1.838506   \n",
       "21         0   -0.086987  1.310170        1.033313  -0.267982       0.158126   \n",
       "22         0    0.873810 -0.426398       -0.023754  -0.866863       0.088110   \n",
       "23         0   -0.185530 -0.659133        0.559455  -0.507534      -0.331985   \n",
       "24         0    0.615134 -0.471154        0.887510   0.151234      -0.261969   \n",
       "25         0    0.060828 -0.256321        3.110996   1.648436       1.698474   \n",
       "26         0    0.479637 -0.506960        0.923961  -1.016583      -0.472017   \n",
       "27         0    0.368776 -0.551717       -0.825667  -0.747087      -0.402001   \n",
       "28         0    1.070896 -0.390592        1.580071  -0.028430       0.508205   \n",
       "29         0    1.255665 -0.587522       -0.570513  -1.046527      -0.261969   \n",
       "..       ...         ...       ...             ...        ...            ...   \n",
       "148        2    0.393412  0.808893        0.049147   0.600395      -0.542033   \n",
       "149        2    0.097782  1.399684       -0.023754   0.600395       0.928300   \n",
       "150        2    0.615134  0.701476        0.923961   1.348995       1.628458   \n",
       "151        2   -0.259437  0.298664        0.413653   0.750115       0.858284   \n",
       "152        2    0.134736 -0.390592        1.397819   1.798156       1.138347   \n",
       "153        2    0.282551  0.862601       -0.315359  -0.297926      -0.121938   \n",
       "154        2   -0.518113 -0.936626       -0.971470   0.151234       0.228141   \n",
       "155        2    0.208643  2.554412       -0.169557   0.750115      -0.472017   \n",
       "156        2    1.033943  1.596615        0.049147   0.001514      -0.752080   \n",
       "157        2   -0.678246  0.620914        0.996862   2.247316      -0.191954   \n",
       "158        2    1.649838 -0.587522        1.215566   1.648436      -0.121938   \n",
       "159        2    0.590498 -0.596474        0.996862   0.899835      -0.752080   \n",
       "160        2   -0.789107  1.337024        0.049147   0.450674      -0.822096   \n",
       "161        2    0.849174  0.826796        0.632356   0.151234       0.508205   \n",
       "162        2   -0.185530  0.835747        0.778159   0.750115       0.438189   \n",
       "163        2   -0.050033  0.996872       -0.060205  -0.297926       0.438189   \n",
       "164        2    0.960035  0.379227       -0.242458   0.750115      -0.682064   \n",
       "165        2    0.898446  1.811448       -0.388260   0.899835      -0.822096   \n",
       "166        2    0.553544  1.220657        0.851060   1.049555       0.788268   \n",
       "167        2   -0.222483  0.925261       -0.242458   0.001514      -0.822096   \n",
       "168        2    0.713677  0.218102        1.179115   1.498716       0.368173   \n",
       "169        2    0.491955  2.026281        1.798775   1.648436       0.858284   \n",
       "170        2   -0.986193  0.620914       -0.169557  -0.148206      -0.261969   \n",
       "171        2   -0.284073  0.048026       -0.315359   0.001514      -0.962128   \n",
       "172        2    1.428115  0.155442        0.413653   0.151234      -0.612049   \n",
       "173        2    0.873810  2.966176        0.304301   0.300954      -0.331985   \n",
       "174        2    0.491955  1.408636        0.413653   1.049555       0.158126   \n",
       "175        2    0.331822  1.739837       -0.388260   0.151234       1.418411   \n",
       "176        2    0.208643  0.227053        0.012696   0.151234       1.418411   \n",
       "177        2    1.391162  1.578712        1.361368   1.498716      -0.261969   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity  \\\n",
       "0      0.806722              1.031908        -0.657708         1.221438   \n",
       "1      0.567048              0.731565        -0.818411        -0.543189   \n",
       "2      0.806722              1.212114        -0.497005         2.129959   \n",
       "3      2.484437              1.462399        -0.979113         1.029251   \n",
       "4      0.806722              0.661485         0.226158         0.400275   \n",
       "5      1.557699              1.362285        -0.175599         0.662349   \n",
       "6      0.327374              0.491291        -0.497005         0.679820   \n",
       "7      0.487157              0.481280        -0.416654        -0.595603   \n",
       "8      0.806722              0.951817        -0.577356         0.679820   \n",
       "9      1.094330              1.122011        -1.139816         0.452690   \n",
       "10     1.046395              1.292205        -1.139816         1.378682   \n",
       "11    -0.151973              0.401188        -0.818411        -0.036514   \n",
       "12     0.487157              0.731565        -0.577356         0.382804   \n",
       "13     1.286069              1.662628         0.547563         2.129959   \n",
       "14     1.605634              1.612571        -0.577356         2.392033   \n",
       "15     0.886613              0.881737        -0.497005        -0.228701   \n",
       "16     0.806722              1.111999        -0.255951         0.662349   \n",
       "17     1.046395              1.372297         0.306509         0.225560   \n",
       "18     1.605634              1.902902        -0.336302         0.470162   \n",
       "19     0.646939              1.001874        -1.541573         0.120730   \n",
       "20     1.126287              1.142034        -0.979113         0.889479   \n",
       "21     0.183570              0.381165        -0.898762         0.679820   \n",
       "22     0.503135              0.851702        -0.738059         0.173145   \n",
       "23     0.295418              0.341120        -0.818411        -0.228701   \n",
       "24     0.375309              0.581394        -0.657708         0.120730   \n",
       "25     0.535092              0.651474         0.868969         0.574991   \n",
       "26     0.886613              0.911771        -0.175599        -0.246172   \n",
       "27     0.167592              0.160914        -0.738059        -0.420888   \n",
       "28     1.046395              0.941805         0.065455         0.295446   \n",
       "29     0.567048              0.301074        -0.818411         0.679820   \n",
       "..          ...                   ...              ...              ...   \n",
       "148   -0.583385             -1.270720         0.708266        -0.595603   \n",
       "149   -1.414254             -0.640000        -0.175599        -0.787791   \n",
       "150   -1.430232             -0.459794        -1.139816        -0.595603   \n",
       "151   -1.302406             -0.670034        -0.979113        -0.578132   \n",
       "152   -0.151973             -0.750126        -0.818411        -0.053985   \n",
       "153   -0.791103             -1.200640         1.993888         0.487633   \n",
       "154   -1.302406             -1.450926         1.351077        -0.333530   \n",
       "155   -0.886972             -1.400868         1.993888        -0.071457   \n",
       "156   -0.791103             -1.200640         0.949320        -0.053985   \n",
       "157   -0.631320             -1.450926         2.154591        -0.787791   \n",
       "158    0.806722             -0.720092         1.351077         1.937772   \n",
       "159    0.487157             -0.930331         1.270726         1.221438   \n",
       "160    0.007810             -1.110537         1.110023        -0.962506   \n",
       "161   -0.743168             -1.470948         1.110023        -1.381823   \n",
       "162   -1.030776             -1.430903         1.913537        -1.102279   \n",
       "163   -1.446211             -1.330789         0.306509        -1.137222   \n",
       "164   -1.510123             -1.350811         0.386860        -0.979978   \n",
       "165   -1.621971             -1.561051         1.270726        -0.770319   \n",
       "166   -0.950885             -1.110537         0.547563        -0.228701   \n",
       "167   -1.302406             -1.370834         0.306509        -1.084807   \n",
       "168   -1.190559             -1.190629         0.226158        -0.088928   \n",
       "169   -0.503494             -1.070491        -0.738059        -0.840205   \n",
       "170   -1.669906             -1.541028         0.306509        -1.504124   \n",
       "171   -1.446211             -1.521006         0.949320        -1.661368   \n",
       "172   -0.982841             -1.330789         0.627915        -0.613075   \n",
       "173   -0.982841             -1.420891         1.270726        -0.927563   \n",
       "174   -0.791103             -1.280731         0.547563        -0.316058   \n",
       "175   -1.126646             -1.340800         0.547563        -0.420888   \n",
       "176   -1.030776             -1.350811         1.351077        -0.228701   \n",
       "177   -0.391646             -1.270720         1.592131        -0.420888   \n",
       "\n",
       "          hue  od28_od315   proline  expected  predicted  expected_str  \\\n",
       "0    0.251009    0.361158  1.842721  1.010159          0             1   \n",
       "1   -0.292496    0.404908  1.110317  0.962526          0             1   \n",
       "2    0.268263    0.317409  0.786369  1.391224          0             1   \n",
       "3    1.182732   -0.426341  1.180741  2.328007          0             1   \n",
       "4   -0.318377    0.361158  0.448336 -0.037767          0             1   \n",
       "5    0.729811    0.404908  0.335659  2.232741          0             1   \n",
       "6    0.082781    0.273659  1.363842  1.724655          0             1   \n",
       "7   -0.003490    0.448658  1.363842  1.740533          0             1   \n",
       "8    0.061213    0.536158  0.335659  0.946649          0             1   \n",
       "9    0.932547    0.229909  1.321588  0.946649          0             1   \n",
       "10   0.298458    1.279908  0.786369  2.423273          0             1   \n",
       "11  -0.025057    0.929908  0.293405  1.692900          0             1   \n",
       "12   0.233755    0.842408  0.406082  1.819921          0             1   \n",
       "13   0.147484    1.279908  0.166643  1.280080          0             1   \n",
       "14   1.053326    1.061158  0.546929  2.540768          0             1   \n",
       "15   0.967055    1.411158  0.377913  1.788166          0             1   \n",
       "16   0.492567    0.492408  0.053965  1.692900          0             1   \n",
       "17   0.665108    0.754908 -0.058713  1.216569          0             1   \n",
       "18   1.570950    1.192408  0.293405  2.963114          0             1   \n",
       "19   0.018078    0.011159  1.053978  0.311541          0             1   \n",
       "20   0.255322    0.579908  1.546943  0.105132          0             1   \n",
       "21  -0.240734    0.317409  1.279334  0.073376          0             1   \n",
       "22  -0.542681    0.667408  1.955399  0.914893          0             1   \n",
       "23  -0.486605    0.579908  1.434265  0.851383          0             1   \n",
       "24  -0.663460    0.711158  1.701875  0.311541          0             1   \n",
       "25  -0.637579    0.754908  0.828623  0.263908          0             1   \n",
       "26  -0.111328   -0.163841  0.856793  1.422979          0             1   \n",
       "27  -0.477978    0.273659  0.222981  1.708777          0             1   \n",
       "28  -0.240734    1.279908  1.110317  0.533829          0             1   \n",
       "29  -0.154463    0.361158  1.377926  0.914893          0             1   \n",
       "..        ...         ...       ...       ...        ...           ...   \n",
       "148  1.450171   -1.782590 -1.396759 -0.307688          2             3   \n",
       "149  1.872897   -1.695090 -1.805215 -0.625242          2             3   \n",
       "150  1.527814   -1.607590 -1.847469 -0.784018          2             3   \n",
       "151  2.476791   -2.088840 -1.608029 -0.847529          2             3   \n",
       "152  0.880784   -1.520090 -1.805215 -1.022184          2             3   \n",
       "153  2.356012   -1.738840 -1.551690 -0.228300          2             3   \n",
       "154  1.096461   -1.651340 -1.495352 -0.339443          2             3   \n",
       "155  1.225867   -1.563840 -1.593945 -0.069523          2             3   \n",
       "156  1.704669   -1.695090 -1.368589 -0.847529          2             3   \n",
       "157  1.053326   -1.257591 -1.241827  0.422685          2             3   \n",
       "158  3.425768   -1.695090 -0.917879 -0.275933          2             3   \n",
       "159  2.886577   -1.695090 -1.171404 -0.402954          2             3   \n",
       "160  1.118029   -1.738840 -1.453098 -0.720508          2             3   \n",
       "161  0.354534    0.011159 -1.115065 -0.212422          2             3   \n",
       "162  0.225128   -0.382591 -0.706609 -0.561731          2             3   \n",
       "163  0.095722   -1.213841 -1.213658 -0.228300          2             3   \n",
       "164  1.950540   -1.126341 -1.312251 -0.418832          2             3   \n",
       "165  0.673735   -0.776341 -1.213658 -0.720508          2             3   \n",
       "166  2.425029   -0.470091 -1.481267 -0.164789          2             3   \n",
       "167  2.243861   -1.038841 -1.213658 -0.196544          2             3   \n",
       "168  1.553695   -0.951341 -1.143234  0.009866          2             3   \n",
       "169  1.484679   -1.257591 -0.974218 -0.371199          2             3   \n",
       "170  0.190619   -1.301341 -1.100980 -0.752263          2             3   \n",
       "171  2.088573   -1.695090 -1.382674 -0.879284          2             3   \n",
       "172  2.002303   -1.476340 -1.269997 -0.275933          2             3   \n",
       "173  1.139596   -1.388840 -1.227742 -0.021890          2             3   \n",
       "174  0.967055   -1.126341 -1.481267  0.009866          2             3   \n",
       "175  2.217979   -1.607590 -1.481267  0.279786          2             3   \n",
       "176  1.829761   -1.563840 -1.396759  0.295664          2             3   \n",
       "177  1.786626   -1.520090 -1.424928 -0.593486          2             3   \n",
       "\n",
       "     predicted_str  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  \n",
       "5                1  \n",
       "6                1  \n",
       "7                1  \n",
       "8                1  \n",
       "9                1  \n",
       "10               1  \n",
       "11               1  \n",
       "12               1  \n",
       "13               1  \n",
       "14               1  \n",
       "15               1  \n",
       "16               1  \n",
       "17               1  \n",
       "18               1  \n",
       "19               1  \n",
       "20               1  \n",
       "21               1  \n",
       "22               1  \n",
       "23               1  \n",
       "24               1  \n",
       "25               1  \n",
       "26               1  \n",
       "27               1  \n",
       "28               1  \n",
       "29               1  \n",
       "..             ...  \n",
       "148              3  \n",
       "149              3  \n",
       "150              3  \n",
       "151              3  \n",
       "152              3  \n",
       "153              3  \n",
       "154              3  \n",
       "155              3  \n",
       "156              3  \n",
       "157              3  \n",
       "158              3  \n",
       "159              3  \n",
       "160              3  \n",
       "161              3  \n",
       "162              3  \n",
       "163              3  \n",
       "164              3  \n",
       "165              3  \n",
       "166              3  \n",
       "167              3  \n",
       "168              3  \n",
       "169              3  \n",
       "170              3  \n",
       "171              3  \n",
       "172              3  \n",
       "173              3  \n",
       "174              3  \n",
       "175              3  \n",
       "176              3  \n",
       "177              3  \n",
       "\n",
       "[178 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as learn\n",
    "from sklearn import metrics\n",
    "import time\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "start= time.time()\n",
    "path = \"/home/beshah/Desktop/CSCI835/data\"\n",
    "\n",
    "filename_read = os.path.join(path,\"wine.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "\n",
    "encode_numeric_zscore(df,'alcohol')\n",
    "encode_numeric_zscore(df,'malic_acid')\n",
    "encode_numeric_zscore(df,'ash')\n",
    "encode_numeric_zscore(df,'alcalinity_ash')\n",
    "encode_numeric_zscore(df,'magnesium')\n",
    "encode_numeric_zscore(df,'total_phenols')\n",
    "encode_numeric_zscore(df,'flavanoids')\n",
    "encode_numeric_zscore(df,'nonflavanoid_phenols')\n",
    "encode_numeric_zscore(df,'proanthocyanins')\n",
    "encode_numeric_zscore(df,'color_intensity')\n",
    "encode_numeric_zscore(df,'hue')\n",
    "encode_numeric_zscore(df,'od28_od315')\n",
    "encode_numeric_zscore(df,'proline')\n",
    "classes = encode_text_index(df,'classes')\n",
    "num_classes = len(classes)\n",
    "\n",
    "x,y = to_xy(df,'classes')\n",
    "\n",
    "model_dir = 'tmp/wine' \n",
    "#global_step = tf.Variable(1000, name='global_step',trainable=False)\n",
    "#opt=tf.train.RMSPropOptimizer(learning_rate=0.0001,  decay=0.9, momentum=0.0, epsilon=1e-10)\n",
    "#opt= tf.train.AdagradDAOptimizer(learning_rate=0.1, global_step=global_step, initial_gradient_squared_accumulator_value=0.1, l1_regularization_strength=0.0,l2_regularization_strength=0.0)\n",
    "#opt = tf.initialize_all_variables()\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "classifier = learn.DNNClassifier(\n",
    "    #optimizer=opt,\n",
    "    model_dir= model_dir,\n",
    "    hidden_units=[40, 80, 20], n_classes=num_classes, feature_columns=feature_columns)\n",
    "\n",
    "classifier.fit(x, y, steps=1000)\n",
    "\n",
    "pred = list(classifier.predict(x, as_iterable=True))\n",
    "score = metrics.accuracy_score(y, pred)\n",
    "print(\"Final score: {}\".format(score))\n",
    "running_time= time.time()- start\n",
    "print(\"Excution time= \", running_time,\"secs\")\n",
    "\n",
    "pred = list(classifier.predict(x, as_iterable=True))\n",
    "predDF = pd.DataFrame(pred)\n",
    "pred_nameDF = pd.DataFrame(classes[pred])\n",
    "actual_nameDF = pd.DataFrame(classes[df['classes']])\n",
    "\n",
    "df2 = pd.concat([df,predDF,pred_nameDF,actual_nameDF],axis=1)\n",
    "df2.columns = ['alcohol','malic_acid','ash','alcalinity_ash','magnesium','total_phenols','flavanoids','nonflavanoid_phenols','proanthocyanins','color_intensity','hue','od28_od315','proline','expected','predicted','expected_str','predicted_str']\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ad hoc prediction - Predict that [[  1.42300000e+01   1.71000000e+00   2.43000000e+00   1.56000000e+01\n",
      "    1.27000000e+02   2.80000000e+00   3.06000000e+00   2.80000000e-01\n",
      "    2.29000000e+00   5.64000000e+00   1.04000000e+00   3.92000000e+00\n",
      "    1.06500000e+03]] is: [1]\n",
      "Two sample flower predictions - Predict that [[  1.42300000e+01   1.71000000e+00   2.43000000e+00   1.56000000e+01\n",
      "    1.27000000e+02   2.80000000e+00   3.06000000e+00   2.80000000e-01\n",
      "    2.29000000e+00   5.64000000e+00   1.04000000e+00   3.92000000e+00\n",
      "    1.06500000e+03]\n",
      " [  1.32000000e+01   1.78000000e+00   2.14000000e+00   1.12000000e+01\n",
      "    1.00000000e+02   2.65000000e+00   2.76000000e+00   2.60000000e-01\n",
      "    1.28000000e+00   4.38000000e+00   1.05000000e+00   3.40000000e+00\n",
      "    1.05000000e+03]] is: [1 1]\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "sample_wine = np.array( [[14.23,1.71,2.43,15.6,127,2.8,3.06,.28,2.29,5.64,1.04,3.92,1065\n",
    "]], dtype=float)\n",
    "pred = list(classifier.predict(sample_wine, as_iterable=True))\n",
    "print(\"Ad hoc prediction - Predict that {} is: {}\".format(sample_wine,classes[pred]))\n",
    "\n",
    "sample_wine = np.array( [[14.23,1.71,2.43,15.6,127,2.8,3.06,.28,2.29,5.64,1.04,3.92,1065\n",
    "],[13.2,1.78,2.14,11.2,100,2.65,2.76,.26,1.28,4.38,1.05,3.4,1050]], dtype=float)\n",
    "pred = list(classifier.predict(sample_wine, as_iterable=True))\n",
    "print(\"Two sample flower predictions - Predict that {} is: {}\".format(sample_wine,classes[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy before save: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as learn\n",
    "import numpy as np\n",
    "from tensorflow.contrib.learn.python.learn.metric_spec import MetricSpec\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "    \n",
    "filename_read = os.path.join(path,\"wine.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "encode_numeric_zscore(df,'alcohol')\n",
    "encode_numeric_zscore(df,'malic_acid')\n",
    "encode_numeric_zscore(df,'ash')\n",
    "encode_numeric_zscore(df,'alcalinity_ash')\n",
    "encode_numeric_zscore(df,'magnesium')\n",
    "encode_numeric_zscore(df,'total_phenols')\n",
    "encode_numeric_zscore(df,'flavanoids')\n",
    "encode_numeric_zscore(df,'nonflavanoid_phenols')\n",
    "encode_numeric_zscore(df,'proanthocyanins')\n",
    "encode_numeric_zscore(df,'color_intensity')\n",
    "encode_numeric_zscore(df,'hue')\n",
    "encode_numeric_zscore(df,'od28_od315')\n",
    "encode_numeric_zscore(df,'proline')\n",
    "classes = encode_text_index(df,'classes')\n",
    "num_classes = len(classes)\n",
    "\n",
    "\n",
    "x, y = to_xy(df,'classes')\n",
    "    \n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=45)\n",
    "\n",
    "model_dir = 'tmp/wine' \n",
    "\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "#opt=tf.train.RMSPropOptimizer(learning_rate=0.0001,  decay=0.9, momentum=0.0, epsilon=1e-10)\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "classifier = learn.DNNClassifier(\n",
    "   # optimizer=opt,\n",
    "    model_dir= model_dir,\n",
    "    hidden_units=[40, 80, 20], n_classes=num_classes, feature_columns=feature_columns)\n",
    "\n",
    "validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    every_n_steps=500,\n",
    "    early_stopping_metric=\"loss\",\n",
    "    early_stopping_metric_minimize=True,\n",
    "    early_stopping_rounds=50)\n",
    "    \n",
    "classifier.fit(x_train, y_train,monitors=[validation_monitor],steps=10000)\n",
    "    \n",
    "pred = list(classifier.predict(x_test, as_iterable=True))\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"Accuarcy before save: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy before save: 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as learn\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "path = \"/home/beshah/Desktop/CSCI835/data\"\n",
    "\n",
    "filename_read = os.path.join(path,\"wine.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "encode_numeric_zscore(df,'alcohol')\n",
    "encode_numeric_zscore(df,'malic_acid')\n",
    "encode_numeric_zscore(df,'ash')\n",
    "encode_numeric_zscore(df,'alcalinity_ash')\n",
    "encode_numeric_zscore(df,'magnesium')\n",
    "encode_numeric_zscore(df,'total_phenols')\n",
    "encode_numeric_zscore(df,'flavanoids')\n",
    "encode_numeric_zscore(df,'nonflavanoid_phenols')\n",
    "encode_numeric_zscore(df,'proanthocyanins')\n",
    "encode_numeric_zscore(df,'color_intensity')\n",
    "encode_numeric_zscore(df,'hue')\n",
    "encode_numeric_zscore(df,'od28_od315')\n",
    "encode_numeric_zscore(df,'proline')\n",
    "classes = encode_text_index(df,'classes')\n",
    "num_classes = len(classes)\n",
    "\n",
    "x,y = to_xy(df,'classes')\n",
    "\n",
    "model_dir = 'tmp/wine' \n",
    "#opt=tf.train.RMSPropOptimizer(learning_rate=0.0001,  decay=0.9, momentum=0.0, epsilon=1e-10)\n",
    "#init_opt = tf.initialize_all_variables()\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "classifier = learn.DNNClassifier(\n",
    "    #optimizer=opt,\n",
    "    model_dir= model_dir,\n",
    "    hidden_units=[40, 80, 20], n_classes=num_classes, feature_columns=feature_columns)\n",
    "\n",
    "classifier.fit(x, y, steps=1000)\n",
    "\n",
    "pred = list(classifier.predict(x, as_iterable=True))\n",
    "score = metrics.accuracy_score(y, pred)\n",
    "print(\"Accuarcy before save: {}\".format(score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As percent probability\n",
      "[  0.   0. 100.]\n",
      "Numpy array of predictions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.,  0.,  1.], dtype=float32),\n",
       " array([ 0.,  0.,  1.], dtype=float32),\n",
       " array([ 1.,  0.,  0.], dtype=float32),\n",
       " array([ 0.,  1.,  0.], dtype=float32),\n",
       " array([ 0.,  1.,  0.], dtype=float32)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss score: 7.242429105297611e-05\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "pred = list(classifier.predict_proba(x_test, as_iterable=True))\n",
    "\n",
    "print(\"As percent probability\")\n",
    "print(pred[0]*100)\n",
    "\n",
    "print(\"Numpy array of predictions\")\n",
    "display(pred[0:5])\n",
    "\n",
    "score = metrics.log_loss(y_test, pred)\n",
    "print(\"Log loss score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[12  0  0]\n",
      " [ 0 17  0]\n",
      " [ 0  0 16]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUYAAAEpCAYAAADvdYt/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM7MCB6OZWcH/By425N7V1o3xAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe24c1ae470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as learn\n",
    "import numpy as np\n",
    "from tensorflow.contrib.learn.python.learn.metric_spec import MetricSpec\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "path = \"/home/beshah/Desktop/CSCI835/data\"\n",
    "    \n",
    "filename_read = os.path.join(path,\"wine.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "encode_numeric_zscore(df,'alcohol')\n",
    "encode_numeric_zscore(df,'malic_acid')\n",
    "encode_numeric_zscore(df,'ash')\n",
    "encode_numeric_zscore(df,'alcalinity_ash')\n",
    "encode_numeric_zscore(df,'magnesium')\n",
    "encode_numeric_zscore(df,'total_phenols')\n",
    "encode_numeric_zscore(df,'flavanoids')\n",
    "encode_numeric_zscore(df,'nonflavanoid_phenols')\n",
    "encode_numeric_zscore(df,'proanthocyanins')\n",
    "encode_numeric_zscore(df,'color_intensity')\n",
    "encode_numeric_zscore(df,'hue')\n",
    "encode_numeric_zscore(df,'od28_od315')\n",
    "encode_numeric_zscore(df,'proline')\n",
    "classes = encode_text_index(df,'classes')\n",
    "num_classes = len(classes)\n",
    "\n",
    "\n",
    "x, y = to_xy(df,'classes')\n",
    "    \n",
    "x_train, x_test, y_train, y_test = train_test_split(    \n",
    "    x, y, test_size=0.25, random_state=45)\n",
    "\n",
    "model_dir = 'tmp/wine' \n",
    "\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "#opt=tf.train.RMSPropOptimizer(learning_rate=0.0001,  decay=0.9, momentum=0.0, epsilon=1e-10)\n",
    "#init_opt = tf.initialize_all_variables()\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "classifier = learn.DNNClassifier(\n",
    "   # optimizer=opt,\n",
    "    model_dir= model_dir,\n",
    "    hidden_units=[40, 80, 20], n_classes=num_classes, feature_columns=feature_columns)\n",
    "\n",
    "validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    every_n_steps=500,\n",
    "    early_stopping_metric=\"loss\",\n",
    "    early_stopping_metric_minimize=True,\n",
    "    early_stopping_rounds=50)\n",
    "    \n",
    "classifier.fit(x_train, y_train,monitors=[validation_monitor],steps=10000)\n",
    "    \n",
    "pred = list(classifier.predict(x_test, as_iterable=True))\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix')\n",
    "print(cm)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Fold score (Accuracy): 1.0\n",
      "Fold #2\n",
      "Fold score (Accuracy): 1.0\n",
      "Fold #3\n",
      "Fold score (Accuracy): 1.0\n",
      "Fold #4\n",
      "Fold score (Accuracy): 1.0\n",
      "Fold #5\n",
      "Fold score (Accuracy): 1.0\n",
      "\n",
      "Cross-validated score (Accuracy): 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.contrib.learn as learn\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "path = \"/home/beshah/Desktop/CSCI835/data\"\n",
    "    \n",
    "filename_read = os.path.join(path,\"wine.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "encode_numeric_zscore(df,'alcohol')\n",
    "encode_numeric_zscore(df,'malic_acid')\n",
    "encode_numeric_zscore(df,'ash')\n",
    "encode_numeric_zscore(df,'alcalinity_ash')\n",
    "encode_numeric_zscore(df,'magnesium')\n",
    "encode_numeric_zscore(df,'total_phenols')\n",
    "encode_numeric_zscore(df,'flavanoids')\n",
    "encode_numeric_zscore(df,'nonflavanoid_phenols')\n",
    "encode_numeric_zscore(df,'proanthocyanins')\n",
    "encode_numeric_zscore(df,'color_intensity')\n",
    "encode_numeric_zscore(df,'hue')\n",
    "encode_numeric_zscore(df,'od28_od315')\n",
    "encode_numeric_zscore(df,'proline')\n",
    "classes = encode_text_index(df,'classes')\n",
    "num_classes = len(classes)\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "x,y = to_xy(df,'classes')\n",
    "\n",
    "kf = KFold(5)\n",
    "    \n",
    "all_y_test = []\n",
    "all_y_pred = []\n",
    "fold = 0\n",
    "for train, test in kf.split(x):        \n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    model_dir = 'tmp/wine' + str(fold)\n",
    "    \n",
    "    feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "    #opt=tf.train.RMSPropOptimizer(learning_rate=0.0001,  decay=0.9, momentum=0.0, epsilon=1e-10)\n",
    "#init_opt = tf.initialize_all_variables()\n",
    "    feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "    classifier = learn.DNNClassifier(\n",
    "    # optimizer=opt,\n",
    "     model_dir= model_dir,\n",
    "     hidden_units=[40, 80, 20], n_classes=num_classes, feature_columns=feature_columns)\n",
    "\n",
    "    validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "        x_test,\n",
    "        y_test,\n",
    "        every_n_steps=50,\n",
    "        early_stopping_metric=\"loss\",\n",
    "        early_stopping_metric_minimize=True,\n",
    "        early_stopping_rounds=50)\n",
    "    \n",
    "    classifier.fit(x, y, steps=1000)\n",
    "\n",
    "    pred = list(classifier.predict(x_test, as_iterable=True))\n",
    "    \n",
    "    all_y_test.append(y_test)\n",
    "    all_y_pred.append(pred)        \n",
    "\n",
    "    score = np.sqrt(metrics.accuracy_score(pred,y_test))\n",
    "    print(\"Fold score (Accuracy): {}\".format(score))\n",
    "\n",
    "\n",
    "all_y_test = np.concatenate(all_y_test)\n",
    "all_y_pred = np.concatenate(all_y_pred)\n",
    "score = np.sqrt(metrics.accuracy_score(all_y_pred,all_y_test))\n",
    "print()\n",
    "print(\"Cross-validated score (Accuracy): {}\".format(score))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
