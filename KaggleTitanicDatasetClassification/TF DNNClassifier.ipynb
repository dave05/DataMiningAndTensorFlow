{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_text_index(df,name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "def encode_numeric_zscore(df,name,mean=None,sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name]-mean)/sd\n",
    "    \n",
    "def to_xy(df,target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    \n",
    "    if target_type in (np.int64, np.int32):\n",
    "        return df.as_matrix(result).astype(np.float32),df.as_matrix([target]).astype(np.int32)\n",
    "    else:\n",
    "        return df.as_matrix(result).astype(np.float32),df.as_matrix([target]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'skflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-185-0c17765b6050>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mskflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_verbosity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"/home/beshah/Desktop/Kaggle Project/Data\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'skflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as learn\n",
    "from sklearn import metrics\n",
    "#import skflow\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "path = \"/home/beshah/Desktop/Kaggle Project/Data\"\n",
    "\n",
    "filename_read = os.path.join(path,\"train.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "df.drop('ID',1,inplace=True)\n",
    "df.drop('A1',1,inplace=True)\n",
    "df.drop('A2',1,inplace=True)\n",
    "#encode_numeric_zscore(df,'ID')\n",
    "#encode_numeric_zscore(df,'A1')\n",
    "#encode_numeric_zscore(df,'A2')\n",
    "encode_numeric_zscore(df,'A3')\n",
    "encode_numeric_zscore(df,'A4')\n",
    "encode_numeric_zscore(df,'A5')\n",
    "encode_numeric_zscore(df,'A6')\n",
    "encode_numeric_zscore(df,'A7')\n",
    "encode_numeric_zscore(df,'A8')\n",
    "encode_numeric_zscore(df,'A9')\n",
    "encode_numeric_zscore(df,'A10')\n",
    "encode_numeric_zscore(df,'A11')\n",
    "encode_numeric_zscore(df,'A12')\n",
    "encode_numeric_zscore(df,'A13')\n",
    "encode_numeric_zscore(df,'A14')\n",
    "encode_numeric_zscore(df,'A15')\n",
    "encode_numeric_zscore(df,'A16')\n",
    "encode_numeric_zscore(df,'A17')\n",
    "encode_numeric_zscore(df,'A18')\n",
    "encode_numeric_zscore(df,'A19')\n",
    "Outcome = encode_text_index(df,'Outcome')\n",
    "num_classes = len(Outcome)\n",
    "\n",
    "x,y = to_xy(df,'Outcome')\n",
    "\n",
    "model_dir = 'tmp/train' \n",
    "opt = tf.train.RMSPropOptimizer( learning_rate=0.05,decay=0.8,\n",
    "    momentum=0.0,\n",
    "    epsilon=1e-10,\n",
    ")\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "classifier = learn.DNNClassifier(\n",
    "    optimizer=opt,\n",
    "    model_dir= model_dir,\n",
    "    hidden_units=[18, 9, 1], n_classes=num_classes, feature_columns=feature_columns)\n",
    "\n",
    "classifier.fit(x, y, steps=2000)\n",
    "\n",
    "pred = list(classifier.predict(x, as_iterable=True))\n",
    "score = metrics.accuracy_score(y, pred)\n",
    "print(\"Final score: {}\".format(score))\n",
    "\n",
    "\n",
    "pred = list(classifier.predict(x, as_iterable=True))\n",
    "predDF = pd.DataFrame(pred)\n",
    "pred_nameDF = pd.DataFrame(Outcome[pred])\n",
    "actual_nameDF = pd.DataFrame(Outcome[df['Outcome']])\n",
    "\n",
    "df2 = pd.concat([df,predDF,pred_nameDF,actual_nameDF],axis=1)\n",
    "df2.columns = ['A1','A2','A3','A4','A5','A6','A7','A8','A9','A12','A13','A14','A15','A16','A17','A18','A19','expected','predicted','expected_str','predicted_str']\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"/home/beshah/Desktop/Kaggle Project/Data\"\n",
    "\n",
    "filename_read = os.path.join(path,\"test.csv\")\n",
    "dftest = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "dftest.drop('A4',1,inplace=True)\n",
    "dftest.drop('A1',1,inplace=True)\n",
    "dftest.drop('A2',1,inplace=True)\n",
    "X_new = dftest.loc[:, :]\n",
    "X_new\n",
    "pred_new = list(classifier.predict(X_new, as_iterable=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'ID':dftest.ID,'Outcome':pred_new}).set_index('ID').to_csv('kagglesub20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Fold #2\n",
      "Fold #3\n",
      "Fold #4\n",
      "Fold #5\n",
      "Fold score (Accuracy): 0.7370277311900888\n",
      "\n",
      "Cross-validated score (Accuracy): 0.7370277311900888\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as learn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "path = \"/home/beshah/Desktop/Kaggle Project/Data\"\n",
    "\n",
    "filename_read = os.path.join(path,\"train.csv\")\n",
    "df = pd.read_csv(filename_read,na_values=['NA','?'])\n",
    "df.drop('ID',1,inplace=True)\n",
    "df.drop('A1',1,inplace=True)\n",
    "df.drop('A2',1,inplace=True)\n",
    "#encode_numeric_zscore(df,'ID')\n",
    "#encode_numeric_zscore(df,'A1')\n",
    "#encode_numeric_zscore(df,'A2')\n",
    "encode_numeric_zscore(df,'A3')\n",
    "encode_numeric_zscore(df,'A4')\n",
    "encode_numeric_zscore(df,'A5')\n",
    "encode_numeric_zscore(df,'A6')\n",
    "encode_numeric_zscore(df,'A7')\n",
    "encode_numeric_zscore(df,'A8')\n",
    "encode_numeric_zscore(df,'A9')\n",
    "encode_numeric_zscore(df,'A10')\n",
    "encode_numeric_zscore(df,'A11')\n",
    "encode_numeric_zscore(df,'A12')\n",
    "encode_numeric_zscore(df,'A13')\n",
    "encode_numeric_zscore(df,'A14')\n",
    "encode_numeric_zscore(df,'A15')\n",
    "encode_numeric_zscore(df,'A16')\n",
    "encode_numeric_zscore(df,'A17')\n",
    "encode_numeric_zscore(df,'A18')\n",
    "encode_numeric_zscore(df,'A19')\n",
    "Outcome = encode_text_index(df,'Outcome')\n",
    "num_classes = len(Outcome)\n",
    "np.random.seed(42)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "x,y = to_xy(df,'Outcome')\n",
    "\n",
    "kf = KFold(5)\n",
    "    \n",
    "all_y_test = []\n",
    "all_y_pred = []\n",
    "fold = 0\n",
    "for train, test in kf.split(x):        \n",
    "    fold+=1\n",
    "    print(\"Fold #{}\".format(fold))\n",
    "        \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    model_dir = 'tmp/train' + str(fold)\n",
    "    opt = tf.train.ProximalGradientDescentOptimizer( learning_rate=0.001,l1_regularization_strength=0.0,l2_regularization_strength=0.0)\n",
    "    feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=x.shape[0])]\n",
    "    classifier = learn.DNNClassifier(\n",
    "         optimizer=opt,\n",
    "         model_dir= model_dir,\n",
    "         hidden_units=[18, 9, 2, 1], n_classes=num_classes, feature_columns=feature_columns)\n",
    "\n",
    "validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "        x_test,\n",
    "        y_test,\n",
    "        every_n_steps=50,\n",
    "        early_stopping_metric=\"loss\",\n",
    "        early_stopping_metric_minimize=True,\n",
    "        early_stopping_rounds=50)\n",
    "classifier.fit(x, y, steps=1000)\n",
    "\n",
    "pred = list(classifier.predict(x_test, as_iterable=True))\n",
    "    \n",
    "all_y_test.append(y_test)\n",
    "all_y_pred.append(pred)        \n",
    "\n",
    "score = np.sqrt(metrics.accuracy_score(pred,y_test))\n",
    "print(\"Fold score (Accuracy): {}\".format(score))\n",
    "\n",
    "\n",
    "all_y_test = np.concatenate(all_y_test)\n",
    "all_y_pred = np.concatenate(all_y_pred)\n",
    "score = np.sqrt(metrics.accuracy_score(all_y_pred,all_y_test))\n",
    "print()\n",
    "print(\"Cross-validated score (Accuracy): {}\".format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
